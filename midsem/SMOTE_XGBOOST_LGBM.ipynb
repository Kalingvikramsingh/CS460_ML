{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "75e7585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries and packages\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "from xgboost import plot_importance\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import imblearn\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.datasets as datasets\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import argmax \n",
    "from lightgbm import early_stopping\n",
    "import copy\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0eee68",
   "metadata": {},
   "source": [
    "# We start the data reading and data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "858aa1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data from data file\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "# df.head()     # Checking the entries\n",
    "# df.shape      #Getting the data on number of entries\n",
    "# df.Lowest_distortion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "cc6507a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We removed all the theoretically non-exhisting molecules \n",
    "# Here we removed entries that had no structure label or data on valence electrons.\n",
    "\n",
    "df.drop(df.index[(df[\"Lowest_distortion\"] == \"-\")],axis=0,inplace=True)     \n",
    "df.drop(df.index[(df[\"Valence_B\"] == \"5\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Valence_A\"] == \"5\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Valence_B\"] == \"4\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Valence_A\"] == \"4\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Valence_A\"] == \"element not in BV\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Valence_B\"] == \"element not in BV\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Vacancy_energy_eV_per_O_atom\"] == \"-\")],axis=0,inplace=True)\n",
    "\n",
    "# df.Lowest_distortion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "6c815ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chemical_formula</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>In_literature</th>\n",
       "      <th>Valence_A</th>\n",
       "      <th>Valence_B</th>\n",
       "      <th>Radius_A_angs</th>\n",
       "      <th>Radius_B_angs</th>\n",
       "      <th>Lowest_distortion</th>\n",
       "      <th>Formation_energy_eVperatom</th>\n",
       "      <th>...</th>\n",
       "      <th>Magnetic_moment_mu_B</th>\n",
       "      <th>Volume_per_atom_A_cube_per_atom</th>\n",
       "      <th>Band_gap_eV</th>\n",
       "      <th>a_angs</th>\n",
       "      <th>b_angs</th>\n",
       "      <th>c_angs</th>\n",
       "      <th>alpha_deg</th>\n",
       "      <th>beta_deg</th>\n",
       "      <th>gamma_deg</th>\n",
       "      <th>Vacancy_energy_eV_per_O_atom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>AgAlO3</td>\n",
       "      <td>Ag</td>\n",
       "      <td>Al</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.898</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.094</td>\n",
       "      <td>5.323</td>\n",
       "      <td>7.300</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-1.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>AgBO3</td>\n",
       "      <td>Ag</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.138</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.439</td>\n",
       "      <td>3.439</td>\n",
       "      <td>3.439</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-2.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>AgBaO3</td>\n",
       "      <td>Ag</td>\n",
       "      <td>Ba</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.631</td>\n",
       "      <td>0.247</td>\n",
       "      <td>6.636</td>\n",
       "      <td>6.739</td>\n",
       "      <td>6.990</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-6.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>AgBeO3</td>\n",
       "      <td>Ag</td>\n",
       "      <td>Be</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.781</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.528</td>\n",
       "      <td>3.528</td>\n",
       "      <td>3.528</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-3.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>AgCaO3</td>\n",
       "      <td>Ag</td>\n",
       "      <td>Ca</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.884</td>\n",
       "      <td>5.884</td>\n",
       "      <td>5.884</td>\n",
       "      <td>59.4</td>\n",
       "      <td>59.4</td>\n",
       "      <td>59.4</td>\n",
       "      <td>-6.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>ZrTmO3</td>\n",
       "      <td>Zr</td>\n",
       "      <td>Tm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200</td>\n",
       "      <td>14.496</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.169</td>\n",
       "      <td>4.169</td>\n",
       "      <td>4.169</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-3.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5325</th>\n",
       "      <td>ZrYO3</td>\n",
       "      <td>Zr</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200</td>\n",
       "      <td>15.277</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.243</td>\n",
       "      <td>4.243</td>\n",
       "      <td>4.243</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-4.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326</th>\n",
       "      <td>ZrYbO3</td>\n",
       "      <td>Zr</td>\n",
       "      <td>Yb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.136</td>\n",
       "      <td>4.007</td>\n",
       "      <td>5.558</td>\n",
       "      <td>5.726</td>\n",
       "      <td>8.254</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-6.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5327</th>\n",
       "      <td>ZrZnO3</td>\n",
       "      <td>Zr</td>\n",
       "      <td>Zn</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10.804</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.780</td>\n",
       "      <td>3.780</td>\n",
       "      <td>3.780</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5328</th>\n",
       "      <td>Zr2O3</td>\n",
       "      <td>Zr</td>\n",
       "      <td>Zr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382</td>\n",
       "      <td>13.915</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.113</td>\n",
       "      <td>4.113</td>\n",
       "      <td>4.113</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2638 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Chemical_formula   A   B In_literature Valence_A Valence_B  \\\n",
       "75             AgAlO3  Ag  Al             0         0         0   \n",
       "78              AgBO3  Ag   B             0         1         1   \n",
       "79             AgBaO3  Ag  Ba             0         0         0   \n",
       "80             AgBeO3  Ag  Be             0         0         0   \n",
       "82             AgCaO3  Ag  Ca             0         0         0   \n",
       "...               ...  ..  ..           ...       ...       ...   \n",
       "5321           ZrTmO3  Zr  Tm             0         0         0   \n",
       "5325            ZrYO3  Zr   Y             0         0         0   \n",
       "5326           ZrYbO3  Zr  Yb             0         0         0   \n",
       "5327           ZrZnO3  Zr  Zn             0         0         0   \n",
       "5328            Zr2O3  Zr  Zr             0         0         0   \n",
       "\n",
       "      Radius_A_angs  Radius_B_angs Lowest_distortion  \\\n",
       "75             1.28           0.54                 1   \n",
       "78             0.75           0.27                 0   \n",
       "79             1.28           1.35                 1   \n",
       "80             1.28           0.45                 0   \n",
       "82             1.28           1.00                 2   \n",
       "...             ...            ...               ...   \n",
       "5321           0.89           0.96                 0   \n",
       "5325           0.89           0.90                 0   \n",
       "5326           0.89           0.95                 1   \n",
       "5327           0.89           0.74                 0   \n",
       "5328           0.89           0.72                 0   \n",
       "\n",
       "     Formation_energy_eVperatom  ... Magnetic_moment_mu_B  \\\n",
       "75                       -1.510  ...                 0.00   \n",
       "78                       -0.350  ...                 0.00   \n",
       "79                       -0.989  ...                 0.00   \n",
       "80                       -0.616  ...                 0.00   \n",
       "82                       -0.975  ...                 0.00   \n",
       "...                         ...  ...                  ...   \n",
       "5321                     -2.315  ...                0.200   \n",
       "5325                     -2.126  ...                0.200   \n",
       "5326                     -3.455  ...                0.000   \n",
       "5327                     -1.630  ...                0.001   \n",
       "5328                     -2.382  ...                0.382   \n",
       "\n",
       "     Volume_per_atom_A_cube_per_atom Band_gap_eV a_angs b_angs c_angs  \\\n",
       "75                             9.898       0.000  5.094  5.323  7.300   \n",
       "78                             8.138       0.000  3.439  3.439  3.439   \n",
       "79                            15.631       0.247  6.636  6.739  6.990   \n",
       "80                             8.781       0.000  3.528  3.528  3.528   \n",
       "82                            14.204       0.000  5.884  5.884  5.884   \n",
       "...                              ...         ...    ...    ...    ...   \n",
       "5321                          14.496       0.000  4.169  4.169  4.169   \n",
       "5325                          15.277       0.000  4.243  4.243  4.243   \n",
       "5326                          13.136       4.007  5.558  5.726  8.254   \n",
       "5327                          10.804       0.000  3.780  3.780  3.780   \n",
       "5328                          13.915       0.000  4.113  4.113  4.113   \n",
       "\n",
       "     alpha_deg beta_deg gamma_deg Vacancy_energy_eV_per_O_atom  \n",
       "75        90.0     90.0      90.0                       -1.341  \n",
       "78        90.0     90.0      90.0                       -2.641  \n",
       "79        90.0     90.0      90.0                       -6.975  \n",
       "80        90.0     90.0      90.0                       -3.058  \n",
       "82        59.4     59.4      59.4                       -6.108  \n",
       "...        ...      ...       ...                          ...  \n",
       "5321      90.0     90.0      90.0                       -3.645  \n",
       "5325      90.0     90.0      90.0                       -4.920  \n",
       "5326      90.0     90.0      90.0                       -6.177  \n",
       "5327      90.0     90.0      90.0                       -0.762  \n",
       "5328      90.0     90.0      90.0                        3.218  \n",
       "\n",
       "[2638 rows x 21 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing Strings with integers so that we dont encounter errors in smote\n",
    "# print(df)\n",
    "\n",
    "\n",
    "df['Valence_A'] = df['Valence_A'].replace(['not balanced'], '0')    #Replacing not balanced with 0\n",
    "df['Valence_A'] = df['Valence_A'].replace(['3'], '1')               #Replacing 3 with 1\n",
    "df['Valence_B'] = df['Valence_B'].replace(['not balanced'], '0')    #Replacing not balanced with 0\n",
    "df['Valence_B'] = df['Valence_B'].replace(['3'], '1')               #Replacing 3 with 1\n",
    "\n",
    "\n",
    "\n",
    "df['Lowest_distortion'] = df['Lowest_distortion'].replace(['cubic'], '0')        #Replacing cubic-0,orthorhombic-1,rhombohedral-2,tetragonal-3\n",
    "df['Lowest_distortion'] = df['Lowest_distortion'].replace(['orthorhombic'], '1')\n",
    "df['Lowest_distortion'] = df['Lowest_distortion'].replace(['rhombohedral'], '2')\n",
    "df['Lowest_distortion'] = df['Lowest_distortion'].replace(['tetragonal'], '3')\n",
    "df['Magnetic_moment_mu_B'] = df['Magnetic_moment_mu_B'].replace(['-'], '0.00')\n",
    "\n",
    "df['In_literature'] = df['In_literature'].replace([False], '0')   #Replacing False with 0\n",
    "df['In_literature'] = df['In_literature'].replace([True], '1')    #Replacing True with 1\n",
    "\n",
    "# print(df)\n",
    "df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ac9c68c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swapping labels for simplicity.\n",
    "def df_column_switch(df, column1, column2):\n",
    "    i = list(df.columns)\n",
    "    a, b = i.index(column1), i.index(column2)\n",
    "    i[b], i[a] = i[a], i[b]\n",
    "    df = df[i]\n",
    "    return df\n",
    "df = df_column_switch(df, \"Lowest_distortion\", \"Vacancy_energy_eV_per_O_atom\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f51c7800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0' '0' ... '0' '0' '0']\n"
     ]
    }
   ],
   "source": [
    "training_data = df.sample(frac=0.8, random_state=25)   #Distributing data set into training and testing dataset\n",
    "testing_data = df.drop(training_data.index)            # Getting the testing data from dataframe\n",
    "\n",
    "\n",
    "train_data = training_data.values\n",
    "X_train = train_data[:, 3:20]\n",
    "Y_train = train_data[:,20]\n",
    "# print(X_train)\n",
    "# print(Y_train)\n",
    "# print(len(Y_train))\n",
    "# print(len(X_train))\n",
    "\n",
    "test_data = testing_data.values\n",
    "X_test = test_data[:, 3:20]\n",
    "Y_test = test_data[:,20]\n",
    "print(Y_train)\n",
    "# X_test.shape\n",
    "# Y_test.shape\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce704f",
   "metadata": {},
   "source": [
    "# Applying SMOTE here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "78123e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=1279 (60.587%)\n",
      "Class=1, n=688 (32.591%)\n",
      "Class=2, n=100 (4.737%)\n",
      "Class=3, n=44 (2.084%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=1279 (25.000%)\n",
      "Class=1, n=1279 (25.000%)\n",
      "Class=2, n=1279 (25.000%)\n",
      "Class=3, n=1279 (25.000%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = LabelEncoder().fit_transform(Y_train)\n",
    "#Applying SMOTE\n",
    "\n",
    "# print(len(X_train))\n",
    "#Showing data imbalance\n",
    "# print(Y_train)\n",
    "counter = Counter(Y_train)\n",
    "for k,v in counter.items():\n",
    " per = v / len(Y_train) * 100\n",
    " print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "#Applying SMOTE\n",
    "oversample = SMOTE()\n",
    "X_train, Y_train = oversample.fit_resample(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Summarize distribution after SMOTE\n",
    "counter = Counter(Y_train)\n",
    "for k,v in counter.items():\n",
    " per = v / len(Y_train) * 100\n",
    " print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()\n",
    "\n",
    "# print(X_test)\n",
    "#Here we oversampled the data with SMOTE ignoring the first 3 columns as they are not important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7449ee4",
   "metadata": {},
   "source": [
    "# Validation and parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "02a2d52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.33638\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.28881\n",
      "[3]\tvalid_0's multi_logloss: 1.24395\n",
      "[4]\tvalid_0's multi_logloss: 1.20155\n",
      "[5]\tvalid_0's multi_logloss: 1.16139\n",
      "[6]\tvalid_0's multi_logloss: 1.12311\n",
      "[7]\tvalid_0's multi_logloss: 1.08679\n",
      "[8]\tvalid_0's multi_logloss: 1.05223\n",
      "[9]\tvalid_0's multi_logloss: 1.01928\n",
      "[10]\tvalid_0's multi_logloss: 0.987828\n",
      "[11]\tvalid_0's multi_logloss: 0.957514\n",
      "[12]\tvalid_0's multi_logloss: 0.928447\n",
      "[13]\tvalid_0's multi_logloss: 0.900609\n",
      "[14]\tvalid_0's multi_logloss: 0.873926\n",
      "[15]\tvalid_0's multi_logloss: 0.848535\n",
      "[16]\tvalid_0's multi_logloss: 0.823944\n",
      "[17]\tvalid_0's multi_logloss: 0.80037\n",
      "[18]\tvalid_0's multi_logloss: 0.777659\n",
      "[19]\tvalid_0's multi_logloss: 0.755957\n",
      "[20]\tvalid_0's multi_logloss: 0.734932\n",
      "[21]\tvalid_0's multi_logloss: 0.714731\n",
      "[22]\tvalid_0's multi_logloss: 0.695226\n",
      "[23]\tvalid_0's multi_logloss: 0.676589\n",
      "[24]\tvalid_0's multi_logloss: 0.658449\n",
      "[25]\tvalid_0's multi_logloss: 0.64099\n",
      "[26]\tvalid_0's multi_logloss: 0.624101\n",
      "[27]\tvalid_0's multi_logloss: 0.607915\n",
      "[28]\tvalid_0's multi_logloss: 0.592201\n",
      "[29]\tvalid_0's multi_logloss: 0.577014\n",
      "[30]\tvalid_0's multi_logloss: 0.562412\n",
      "[31]\tvalid_0's multi_logloss: 0.548218\n",
      "[32]\tvalid_0's multi_logloss: 0.53446\n",
      "[33]\tvalid_0's multi_logloss: 0.52126\n",
      "[34]\tvalid_0's multi_logloss: 0.508414\n",
      "[35]\tvalid_0's multi_logloss: 0.495951\n",
      "[36]\tvalid_0's multi_logloss: 0.484011\n",
      "[37]\tvalid_0's multi_logloss: 0.472373\n",
      "[38]\tvalid_0's multi_logloss: 0.46105\n",
      "[39]\tvalid_0's multi_logloss: 0.450208\n",
      "[40]\tvalid_0's multi_logloss: 0.439579\n",
      "[41]\tvalid_0's multi_logloss: 0.429422\n",
      "[42]\tvalid_0's multi_logloss: 0.419434\n",
      "[43]\tvalid_0's multi_logloss: 0.409815\n",
      "[44]\tvalid_0's multi_logloss: 0.400511\n",
      "[45]\tvalid_0's multi_logloss: 0.391444\n",
      "[46]\tvalid_0's multi_logloss: 0.382602\n",
      "[47]\tvalid_0's multi_logloss: 0.374081\n",
      "[48]\tvalid_0's multi_logloss: 0.365817\n",
      "[49]\tvalid_0's multi_logloss: 0.35777\n",
      "[50]\tvalid_0's multi_logloss: 0.350084\n",
      "[51]\tvalid_0's multi_logloss: 0.342497\n",
      "[52]\tvalid_0's multi_logloss: 0.335257\n",
      "[53]\tvalid_0's multi_logloss: 0.32798\n",
      "[54]\tvalid_0's multi_logloss: 0.321131\n",
      "[55]\tvalid_0's multi_logloss: 0.314236\n",
      "[56]\tvalid_0's multi_logloss: 0.307713\n",
      "[57]\tvalid_0's multi_logloss: 0.301219\n",
      "[58]\tvalid_0's multi_logloss: 0.295041\n",
      "[59]\tvalid_0's multi_logloss: 0.288885\n",
      "[60]\tvalid_0's multi_logloss: 0.28303\n",
      "[61]\tvalid_0's multi_logloss: 0.277192\n",
      "[62]\tvalid_0's multi_logloss: 0.271642\n",
      "[63]\tvalid_0's multi_logloss: 0.266104\n",
      "[64]\tvalid_0's multi_logloss: 0.260847\n",
      "[65]\tvalid_0's multi_logloss: 0.255595\n",
      "[66]\tvalid_0's multi_logloss: 0.250608\n",
      "[67]\tvalid_0's multi_logloss: 0.245586\n",
      "[68]\tvalid_0's multi_logloss: 0.240881\n",
      "[69]\tvalid_0's multi_logloss: 0.236113\n",
      "[70]\tvalid_0's multi_logloss: 0.231647\n",
      "[71]\tvalid_0's multi_logloss: 0.227111\n",
      "[72]\tvalid_0's multi_logloss: 0.222846\n",
      "[73]\tvalid_0's multi_logloss: 0.218587\n",
      "[74]\tvalid_0's multi_logloss: 0.214529\n",
      "[75]\tvalid_0's multi_logloss: 0.210462\n",
      "[76]\tvalid_0's multi_logloss: 0.206554\n",
      "[77]\tvalid_0's multi_logloss: 0.202656\n",
      "[78]\tvalid_0's multi_logloss: 0.198929\n",
      "[79]\tvalid_0's multi_logloss: 0.195279\n",
      "[80]\tvalid_0's multi_logloss: 0.191729\n",
      "[81]\tvalid_0's multi_logloss: 0.188215\n",
      "[82]\tvalid_0's multi_logloss: 0.184892\n",
      "[83]\tvalid_0's multi_logloss: 0.181536\n",
      "[84]\tvalid_0's multi_logloss: 0.178309\n",
      "[85]\tvalid_0's multi_logloss: 0.175172\n",
      "[86]\tvalid_0's multi_logloss: 0.172091\n",
      "[87]\tvalid_0's multi_logloss: 0.169006\n",
      "[88]\tvalid_0's multi_logloss: 0.166063\n",
      "[89]\tvalid_0's multi_logloss: 0.163205\n",
      "[90]\tvalid_0's multi_logloss: 0.160398\n",
      "[91]\tvalid_0's multi_logloss: 0.157611\n",
      "[92]\tvalid_0's multi_logloss: 0.154905\n",
      "[93]\tvalid_0's multi_logloss: 0.152222\n",
      "[94]\tvalid_0's multi_logloss: 0.149735\n",
      "[95]\tvalid_0's multi_logloss: 0.147175\n",
      "[96]\tvalid_0's multi_logloss: 0.144715\n",
      "[97]\tvalid_0's multi_logloss: 0.142266\n",
      "[98]\tvalid_0's multi_logloss: 0.139967\n",
      "[99]\tvalid_0's multi_logloss: 0.13759\n",
      "[100]\tvalid_0's multi_logloss: 0.135363\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.135363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.96      0.99      0.98       327\n",
      "\n",
      "    accuracy                           0.99      1279\n",
      "   macro avg       0.99      0.99      0.99      1279\n",
      "weighted avg       0.99      0.99      0.99      1279\n",
      "\n",
      "[[327   0   0  12]\n",
      " [  0 310   0   1]\n",
      " [  0   0 302   0]\n",
      " [  2   0   0 325]]\n",
      "Accuracy: 98.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 2\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 2,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "19567d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.33112\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.27816\n",
      "[3]\tvalid_0's multi_logloss: 1.22845\n",
      "[4]\tvalid_0's multi_logloss: 1.18165\n",
      "[5]\tvalid_0's multi_logloss: 1.1375\n",
      "[6]\tvalid_0's multi_logloss: 1.09576\n",
      "[7]\tvalid_0's multi_logloss: 1.05617\n",
      "[8]\tvalid_0's multi_logloss: 1.0186\n",
      "[9]\tvalid_0's multi_logloss: 0.98291\n",
      "[10]\tvalid_0's multi_logloss: 0.948661\n",
      "[11]\tvalid_0's multi_logloss: 0.915442\n",
      "[12]\tvalid_0's multi_logloss: 0.883756\n",
      "[13]\tvalid_0's multi_logloss: 0.853506\n",
      "[14]\tvalid_0's multi_logloss: 0.824594\n",
      "[15]\tvalid_0's multi_logloss: 0.796941\n",
      "[16]\tvalid_0's multi_logloss: 0.770466\n",
      "[17]\tvalid_0's multi_logloss: 0.745105\n",
      "[18]\tvalid_0's multi_logloss: 0.72079\n",
      "[19]\tvalid_0's multi_logloss: 0.697467\n",
      "[20]\tvalid_0's multi_logloss: 0.675077\n",
      "[21]\tvalid_0's multi_logloss: 0.653577\n",
      "[22]\tvalid_0's multi_logloss: 0.632916\n",
      "[23]\tvalid_0's multi_logloss: 0.613056\n",
      "[24]\tvalid_0's multi_logloss: 0.593953\n",
      "[25]\tvalid_0's multi_logloss: 0.575575\n",
      "[26]\tvalid_0's multi_logloss: 0.557904\n",
      "[27]\tvalid_0's multi_logloss: 0.540893\n",
      "[28]\tvalid_0's multi_logloss: 0.524446\n",
      "[29]\tvalid_0's multi_logloss: 0.508602\n",
      "[30]\tvalid_0's multi_logloss: 0.493274\n",
      "[31]\tvalid_0's multi_logloss: 0.47855\n",
      "[32]\tvalid_0's multi_logloss: 0.464296\n",
      "[33]\tvalid_0's multi_logloss: 0.450627\n",
      "[34]\tvalid_0's multi_logloss: 0.437355\n",
      "[35]\tvalid_0's multi_logloss: 0.42462\n",
      "[36]\tvalid_0's multi_logloss: 0.412254\n",
      "[37]\tvalid_0's multi_logloss: 0.400375\n",
      "[38]\tvalid_0's multi_logloss: 0.388826\n",
      "[39]\tvalid_0's multi_logloss: 0.377667\n",
      "[40]\tvalid_0's multi_logloss: 0.366938\n",
      "[41]\tvalid_0's multi_logloss: 0.356501\n",
      "[42]\tvalid_0's multi_logloss: 0.346435\n",
      "[43]\tvalid_0's multi_logloss: 0.336731\n",
      "[44]\tvalid_0's multi_logloss: 0.327295\n",
      "[45]\tvalid_0's multi_logloss: 0.318153\n",
      "[46]\tvalid_0's multi_logloss: 0.309355\n",
      "[47]\tvalid_0's multi_logloss: 0.300787\n",
      "[48]\tvalid_0's multi_logloss: 0.292483\n",
      "[49]\tvalid_0's multi_logloss: 0.284516\n",
      "[50]\tvalid_0's multi_logloss: 0.276749\n",
      "[51]\tvalid_0's multi_logloss: 0.269231\n",
      "[52]\tvalid_0's multi_logloss: 0.261953\n",
      "[53]\tvalid_0's multi_logloss: 0.254906\n",
      "[54]\tvalid_0's multi_logloss: 0.248099\n",
      "[55]\tvalid_0's multi_logloss: 0.241511\n",
      "[56]\tvalid_0's multi_logloss: 0.235106\n",
      "[57]\tvalid_0's multi_logloss: 0.228929\n",
      "[58]\tvalid_0's multi_logloss: 0.222912\n",
      "[59]\tvalid_0's multi_logloss: 0.217066\n",
      "[60]\tvalid_0's multi_logloss: 0.211417\n",
      "[61]\tvalid_0's multi_logloss: 0.205935\n",
      "[62]\tvalid_0's multi_logloss: 0.20064\n",
      "[63]\tvalid_0's multi_logloss: 0.195485\n",
      "[64]\tvalid_0's multi_logloss: 0.190439\n",
      "[65]\tvalid_0's multi_logloss: 0.185541\n",
      "[66]\tvalid_0's multi_logloss: 0.1808\n",
      "[67]\tvalid_0's multi_logloss: 0.176229\n",
      "[68]\tvalid_0's multi_logloss: 0.171772\n",
      "[69]\tvalid_0's multi_logloss: 0.167443\n",
      "[70]\tvalid_0's multi_logloss: 0.163253\n",
      "[71]\tvalid_0's multi_logloss: 0.159207\n",
      "[72]\tvalid_0's multi_logloss: 0.155263\n",
      "[73]\tvalid_0's multi_logloss: 0.151447\n",
      "[74]\tvalid_0's multi_logloss: 0.147739\n",
      "[75]\tvalid_0's multi_logloss: 0.144136\n",
      "[76]\tvalid_0's multi_logloss: 0.140647\n",
      "[77]\tvalid_0's multi_logloss: 0.137283\n",
      "[78]\tvalid_0's multi_logloss: 0.133876\n",
      "[79]\tvalid_0's multi_logloss: 0.130572\n",
      "[80]\tvalid_0's multi_logloss: 0.12737\n",
      "[81]\tvalid_0's multi_logloss: 0.124278\n",
      "[82]\tvalid_0's multi_logloss: 0.121281\n",
      "[83]\tvalid_0's multi_logloss: 0.11837\n",
      "[84]\tvalid_0's multi_logloss: 0.115545\n",
      "[85]\tvalid_0's multi_logloss: 0.112802\n",
      "[86]\tvalid_0's multi_logloss: 0.110141\n",
      "[87]\tvalid_0's multi_logloss: 0.107557\n",
      "[88]\tvalid_0's multi_logloss: 0.105047\n",
      "[89]\tvalid_0's multi_logloss: 0.102625\n",
      "[90]\tvalid_0's multi_logloss: 0.10026\n",
      "[91]\tvalid_0's multi_logloss: 0.0979646\n",
      "[92]\tvalid_0's multi_logloss: 0.0957356\n",
      "[93]\tvalid_0's multi_logloss: 0.0935697\n",
      "[94]\tvalid_0's multi_logloss: 0.0914671\n",
      "[95]\tvalid_0's multi_logloss: 0.089427\n",
      "[96]\tvalid_0's multi_logloss: 0.0874447\n",
      "[97]\tvalid_0's multi_logloss: 0.0855058\n",
      "[98]\tvalid_0's multi_logloss: 0.0836385\n",
      "[99]\tvalid_0's multi_logloss: 0.0818243\n",
      "[100]\tvalid_0's multi_logloss: 0.079987\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.079987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.98      0.98      0.98       327\n",
      "\n",
      "    accuracy                           0.99      1279\n",
      "   macro avg       0.99      0.99      0.99      1279\n",
      "weighted avg       0.99      0.99      0.99      1279\n",
      "\n",
      "[[334   0   0   5]\n",
      " [  1 310   0   0]\n",
      " [  0   0 302   0]\n",
      " [  4   1   0 322]]\n",
      "Accuracy: 99.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 3\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 3,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "3e8295bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.33056\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.27765\n",
      "[3]\tvalid_0's multi_logloss: 1.22759\n",
      "[4]\tvalid_0's multi_logloss: 1.18046\n",
      "[5]\tvalid_0's multi_logloss: 1.13605\n",
      "[6]\tvalid_0's multi_logloss: 1.09399\n",
      "[7]\tvalid_0's multi_logloss: 1.0542\n",
      "[8]\tvalid_0's multi_logloss: 1.01635\n",
      "[9]\tvalid_0's multi_logloss: 0.98038\n",
      "[10]\tvalid_0's multi_logloss: 0.946143\n",
      "[11]\tvalid_0's multi_logloss: 0.913281\n",
      "[12]\tvalid_0's multi_logloss: 0.881928\n",
      "[13]\tvalid_0's multi_logloss: 0.85198\n",
      "[14]\tvalid_0's multi_logloss: 0.823352\n",
      "[15]\tvalid_0's multi_logloss: 0.796009\n",
      "[16]\tvalid_0's multi_logloss: 0.769828\n",
      "[17]\tvalid_0's multi_logloss: 0.74472\n",
      "[18]\tvalid_0's multi_logloss: 0.72066\n",
      "[19]\tvalid_0's multi_logloss: 0.697554\n",
      "[20]\tvalid_0's multi_logloss: 0.67537\n",
      "[21]\tvalid_0's multi_logloss: 0.653675\n",
      "[22]\tvalid_0's multi_logloss: 0.632812\n",
      "[23]\tvalid_0's multi_logloss: 0.612768\n",
      "[24]\tvalid_0's multi_logloss: 0.593473\n",
      "[25]\tvalid_0's multi_logloss: 0.5749\n",
      "[26]\tvalid_0's multi_logloss: 0.557046\n",
      "[27]\tvalid_0's multi_logloss: 0.539866\n",
      "[28]\tvalid_0's multi_logloss: 0.523298\n",
      "[29]\tvalid_0's multi_logloss: 0.50733\n",
      "[30]\tvalid_0's multi_logloss: 0.491924\n",
      "[31]\tvalid_0's multi_logloss: 0.477082\n",
      "[32]\tvalid_0's multi_logloss: 0.462752\n",
      "[33]\tvalid_0's multi_logloss: 0.448917\n",
      "[34]\tvalid_0's multi_logloss: 0.435567\n",
      "[35]\tvalid_0's multi_logloss: 0.422679\n",
      "[36]\tvalid_0's multi_logloss: 0.41014\n",
      "[37]\tvalid_0's multi_logloss: 0.39803\n",
      "[38]\tvalid_0's multi_logloss: 0.386403\n",
      "[39]\tvalid_0's multi_logloss: 0.37517\n",
      "[40]\tvalid_0's multi_logloss: 0.3642\n",
      "[41]\tvalid_0's multi_logloss: 0.353587\n",
      "[42]\tvalid_0's multi_logloss: 0.343408\n",
      "[43]\tvalid_0's multi_logloss: 0.333556\n",
      "[44]\tvalid_0's multi_logloss: 0.324031\n",
      "[45]\tvalid_0's multi_logloss: 0.314816\n",
      "[46]\tvalid_0's multi_logloss: 0.305905\n",
      "[47]\tvalid_0's multi_logloss: 0.297258\n",
      "[48]\tvalid_0's multi_logloss: 0.28889\n",
      "[49]\tvalid_0's multi_logloss: 0.280792\n",
      "[50]\tvalid_0's multi_logloss: 0.272981\n",
      "[51]\tvalid_0's multi_logloss: 0.265386\n",
      "[52]\tvalid_0's multi_logloss: 0.258035\n",
      "[53]\tvalid_0's multi_logloss: 0.25094\n",
      "[54]\tvalid_0's multi_logloss: 0.243992\n",
      "[55]\tvalid_0's multi_logloss: 0.237266\n",
      "[56]\tvalid_0's multi_logloss: 0.230684\n",
      "[57]\tvalid_0's multi_logloss: 0.224311\n",
      "[58]\tvalid_0's multi_logloss: 0.21814\n",
      "[59]\tvalid_0's multi_logloss: 0.212188\n",
      "[60]\tvalid_0's multi_logloss: 0.206419\n",
      "[61]\tvalid_0's multi_logloss: 0.200812\n",
      "[62]\tvalid_0's multi_logloss: 0.195382\n",
      "[63]\tvalid_0's multi_logloss: 0.190123\n",
      "[64]\tvalid_0's multi_logloss: 0.185047\n",
      "[65]\tvalid_0's multi_logloss: 0.180111\n",
      "[66]\tvalid_0's multi_logloss: 0.175311\n",
      "[67]\tvalid_0's multi_logloss: 0.170592\n",
      "[68]\tvalid_0's multi_logloss: 0.166021\n",
      "[69]\tvalid_0's multi_logloss: 0.161613\n",
      "[70]\tvalid_0's multi_logloss: 0.157319\n",
      "[71]\tvalid_0's multi_logloss: 0.153159\n",
      "[72]\tvalid_0's multi_logloss: 0.149127\n",
      "[73]\tvalid_0's multi_logloss: 0.145219\n",
      "[74]\tvalid_0's multi_logloss: 0.141431\n",
      "[75]\tvalid_0's multi_logloss: 0.137754\n",
      "[76]\tvalid_0's multi_logloss: 0.134181\n",
      "[77]\tvalid_0's multi_logloss: 0.130718\n",
      "[78]\tvalid_0's multi_logloss: 0.127368\n",
      "[79]\tvalid_0's multi_logloss: 0.124113\n",
      "[80]\tvalid_0's multi_logloss: 0.120985\n",
      "[81]\tvalid_0's multi_logloss: 0.117926\n",
      "[82]\tvalid_0's multi_logloss: 0.114964\n",
      "[83]\tvalid_0's multi_logloss: 0.112109\n",
      "[84]\tvalid_0's multi_logloss: 0.109325\n",
      "[85]\tvalid_0's multi_logloss: 0.106605\n",
      "[86]\tvalid_0's multi_logloss: 0.104007\n",
      "[87]\tvalid_0's multi_logloss: 0.101465\n",
      "[88]\tvalid_0's multi_logloss: 0.0988997\n",
      "[89]\tvalid_0's multi_logloss: 0.0964075\n",
      "[90]\tvalid_0's multi_logloss: 0.0939849\n",
      "[91]\tvalid_0's multi_logloss: 0.0916394\n",
      "[92]\tvalid_0's multi_logloss: 0.0893601\n",
      "[93]\tvalid_0's multi_logloss: 0.0871493\n",
      "[94]\tvalid_0's multi_logloss: 0.0850052\n",
      "[95]\tvalid_0's multi_logloss: 0.0829241\n",
      "[96]\tvalid_0's multi_logloss: 0.0809055\n",
      "[97]\tvalid_0's multi_logloss: 0.078949\n",
      "[98]\tvalid_0's multi_logloss: 0.0770392\n",
      "[99]\tvalid_0's multi_logloss: 0.0751267\n",
      "[100]\tvalid_0's multi_logloss: 0.0732706\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.0732706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.98      0.99      0.99       327\n",
      "\n",
      "    accuracy                           0.99      1279\n",
      "   macro avg       0.99      0.99      0.99      1279\n",
      "weighted avg       0.99      0.99      0.99      1279\n",
      "\n",
      "[[334   0   0   5]\n",
      " [  0 310   0   1]\n",
      " [  0   0 302   0]\n",
      " [  3   0   0 324]]\n",
      "Accuracy: 99.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 4\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 4,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "ef12868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.3294\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.27543\n",
      "[3]\tvalid_0's multi_logloss: 1.22483\n",
      "[4]\tvalid_0's multi_logloss: 1.1772\n",
      "[5]\tvalid_0's multi_logloss: 1.1323\n",
      "[6]\tvalid_0's multi_logloss: 1.08981\n",
      "[7]\tvalid_0's multi_logloss: 1.0496\n",
      "[8]\tvalid_0's multi_logloss: 1.01138\n",
      "[9]\tvalid_0's multi_logloss: 0.975048\n",
      "[10]\tvalid_0's multi_logloss: 0.940476\n",
      "[11]\tvalid_0's multi_logloss: 0.907331\n",
      "[12]\tvalid_0's multi_logloss: 0.875713\n",
      "[13]\tvalid_0's multi_logloss: 0.845519\n",
      "[14]\tvalid_0's multi_logloss: 0.816625\n",
      "[15]\tvalid_0's multi_logloss: 0.788991\n",
      "[16]\tvalid_0's multi_logloss: 0.762547\n",
      "[17]\tvalid_0's multi_logloss: 0.737215\n",
      "[18]\tvalid_0's multi_logloss: 0.712926\n",
      "[19]\tvalid_0's multi_logloss: 0.689626\n",
      "[20]\tvalid_0's multi_logloss: 0.667259\n",
      "[21]\tvalid_0's multi_logloss: 0.645711\n",
      "[22]\tvalid_0's multi_logloss: 0.625068\n",
      "[23]\tvalid_0's multi_logloss: 0.605161\n",
      "[24]\tvalid_0's multi_logloss: 0.58601\n",
      "[25]\tvalid_0's multi_logloss: 0.567646\n",
      "[26]\tvalid_0's multi_logloss: 0.550065\n",
      "[27]\tvalid_0's multi_logloss: 0.533185\n",
      "[28]\tvalid_0's multi_logloss: 0.516861\n",
      "[29]\tvalid_0's multi_logloss: 0.500984\n",
      "[30]\tvalid_0's multi_logloss: 0.485632\n",
      "[31]\tvalid_0's multi_logloss: 0.470801\n",
      "[32]\tvalid_0's multi_logloss: 0.456539\n",
      "[33]\tvalid_0's multi_logloss: 0.442711\n",
      "[34]\tvalid_0's multi_logloss: 0.429366\n",
      "[35]\tvalid_0's multi_logloss: 0.416487\n",
      "[36]\tvalid_0's multi_logloss: 0.404078\n",
      "[37]\tvalid_0's multi_logloss: 0.392106\n",
      "[38]\tvalid_0's multi_logloss: 0.380542\n",
      "[39]\tvalid_0's multi_logloss: 0.369371\n",
      "[40]\tvalid_0's multi_logloss: 0.358576\n",
      "[41]\tvalid_0's multi_logloss: 0.348142\n",
      "[42]\tvalid_0's multi_logloss: 0.338018\n",
      "[43]\tvalid_0's multi_logloss: 0.328153\n",
      "[44]\tvalid_0's multi_logloss: 0.318689\n",
      "[45]\tvalid_0's multi_logloss: 0.309445\n",
      "[46]\tvalid_0's multi_logloss: 0.300476\n",
      "[47]\tvalid_0's multi_logloss: 0.291802\n",
      "[48]\tvalid_0's multi_logloss: 0.283487\n",
      "[49]\tvalid_0's multi_logloss: 0.275365\n",
      "[50]\tvalid_0's multi_logloss: 0.267576\n",
      "[51]\tvalid_0's multi_logloss: 0.259967\n",
      "[52]\tvalid_0's multi_logloss: 0.252611\n",
      "[53]\tvalid_0's multi_logloss: 0.24548\n",
      "[54]\tvalid_0's multi_logloss: 0.238639\n",
      "[55]\tvalid_0's multi_logloss: 0.231953\n",
      "[56]\tvalid_0's multi_logloss: 0.225488\n",
      "[57]\tvalid_0's multi_logloss: 0.219278\n",
      "[58]\tvalid_0's multi_logloss: 0.213186\n",
      "[59]\tvalid_0's multi_logloss: 0.207301\n",
      "[60]\tvalid_0's multi_logloss: 0.201574\n",
      "[61]\tvalid_0's multi_logloss: 0.196057\n",
      "[62]\tvalid_0's multi_logloss: 0.19066\n",
      "[63]\tvalid_0's multi_logloss: 0.185414\n",
      "[64]\tvalid_0's multi_logloss: 0.180384\n",
      "[65]\tvalid_0's multi_logloss: 0.175474\n",
      "[66]\tvalid_0's multi_logloss: 0.170758\n",
      "[67]\tvalid_0's multi_logloss: 0.166107\n",
      "[68]\tvalid_0's multi_logloss: 0.16162\n",
      "[69]\tvalid_0's multi_logloss: 0.157258\n",
      "[70]\tvalid_0's multi_logloss: 0.153029\n",
      "[71]\tvalid_0's multi_logloss: 0.148908\n",
      "[72]\tvalid_0's multi_logloss: 0.144939\n",
      "[73]\tvalid_0's multi_logloss: 0.141054\n",
      "[74]\tvalid_0's multi_logloss: 0.137317\n",
      "[75]\tvalid_0's multi_logloss: 0.133675\n",
      "[76]\tvalid_0's multi_logloss: 0.130171\n",
      "[77]\tvalid_0's multi_logloss: 0.126712\n",
      "[78]\tvalid_0's multi_logloss: 0.123371\n",
      "[79]\tvalid_0's multi_logloss: 0.120157\n",
      "[80]\tvalid_0's multi_logloss: 0.117005\n",
      "[81]\tvalid_0's multi_logloss: 0.114006\n",
      "[82]\tvalid_0's multi_logloss: 0.111077\n",
      "[83]\tvalid_0's multi_logloss: 0.108236\n",
      "[84]\tvalid_0's multi_logloss: 0.105493\n",
      "[85]\tvalid_0's multi_logloss: 0.102799\n",
      "[86]\tvalid_0's multi_logloss: 0.100222\n",
      "[87]\tvalid_0's multi_logloss: 0.0976875\n",
      "[88]\tvalid_0's multi_logloss: 0.0952458\n",
      "[89]\tvalid_0's multi_logloss: 0.0928873\n",
      "[90]\tvalid_0's multi_logloss: 0.0905722\n",
      "[91]\tvalid_0's multi_logloss: 0.0883227\n",
      "[92]\tvalid_0's multi_logloss: 0.0861264\n",
      "[93]\tvalid_0's multi_logloss: 0.0840031\n",
      "[94]\tvalid_0's multi_logloss: 0.0819897\n",
      "[95]\tvalid_0's multi_logloss: 0.0799981\n",
      "[96]\tvalid_0's multi_logloss: 0.0780817\n",
      "[97]\tvalid_0's multi_logloss: 0.0762301\n",
      "[98]\tvalid_0's multi_logloss: 0.0744459\n",
      "[99]\tvalid_0's multi_logloss: 0.0726185\n",
      "[100]\tvalid_0's multi_logloss: 0.0708309\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.0708309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.99      0.99      0.99       327\n",
      "\n",
      "    accuracy                           1.00      1279\n",
      "   macro avg       1.00      1.00      1.00      1279\n",
      "weighted avg       1.00      1.00      1.00      1279\n",
      "\n",
      "[[337   0   0   2]\n",
      " [  0 310   0   1]\n",
      " [  0   0 302   0]\n",
      " [  3   0   0 324]]\n",
      "Accuracy: 99.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 5\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 5,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "5ea1eb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.32916\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.27491\n",
      "[3]\tvalid_0's multi_logloss: 1.22406\n",
      "[4]\tvalid_0's multi_logloss: 1.17625\n",
      "[5]\tvalid_0's multi_logloss: 1.13113\n",
      "[6]\tvalid_0's multi_logloss: 1.08849\n",
      "[7]\tvalid_0's multi_logloss: 1.04816\n",
      "[8]\tvalid_0's multi_logloss: 1.00976\n",
      "[9]\tvalid_0's multi_logloss: 0.97326\n",
      "[10]\tvalid_0's multi_logloss: 0.938576\n",
      "[11]\tvalid_0's multi_logloss: 0.905505\n",
      "[12]\tvalid_0's multi_logloss: 0.873919\n",
      "[13]\tvalid_0's multi_logloss: 0.843625\n",
      "[14]\tvalid_0's multi_logloss: 0.814634\n",
      "[15]\tvalid_0's multi_logloss: 0.78694\n",
      "[16]\tvalid_0's multi_logloss: 0.760424\n",
      "[17]\tvalid_0's multi_logloss: 0.735031\n",
      "[18]\tvalid_0's multi_logloss: 0.710666\n",
      "[19]\tvalid_0's multi_logloss: 0.687302\n",
      "[20]\tvalid_0's multi_logloss: 0.664868\n",
      "[21]\tvalid_0's multi_logloss: 0.643317\n",
      "[22]\tvalid_0's multi_logloss: 0.622572\n",
      "[23]\tvalid_0's multi_logloss: 0.60266\n",
      "[24]\tvalid_0's multi_logloss: 0.583425\n",
      "[25]\tvalid_0's multi_logloss: 0.564907\n",
      "[26]\tvalid_0's multi_logloss: 0.547112\n",
      "[27]\tvalid_0's multi_logloss: 0.529969\n",
      "[28]\tvalid_0's multi_logloss: 0.513522\n",
      "[29]\tvalid_0's multi_logloss: 0.497606\n",
      "[30]\tvalid_0's multi_logloss: 0.482217\n",
      "[31]\tvalid_0's multi_logloss: 0.467374\n",
      "[32]\tvalid_0's multi_logloss: 0.45306\n",
      "[33]\tvalid_0's multi_logloss: 0.439245\n",
      "[34]\tvalid_0's multi_logloss: 0.425937\n",
      "[35]\tvalid_0's multi_logloss: 0.413089\n",
      "[36]\tvalid_0's multi_logloss: 0.400709\n",
      "[37]\tvalid_0's multi_logloss: 0.388729\n",
      "[38]\tvalid_0's multi_logloss: 0.377156\n",
      "[39]\tvalid_0's multi_logloss: 0.365977\n",
      "[40]\tvalid_0's multi_logloss: 0.355167\n",
      "[41]\tvalid_0's multi_logloss: 0.344723\n",
      "[42]\tvalid_0's multi_logloss: 0.334621\n",
      "[43]\tvalid_0's multi_logloss: 0.324859\n",
      "[44]\tvalid_0's multi_logloss: 0.315415\n",
      "[45]\tvalid_0's multi_logloss: 0.306271\n",
      "[46]\tvalid_0's multi_logloss: 0.297437\n",
      "[47]\tvalid_0's multi_logloss: 0.288862\n",
      "[48]\tvalid_0's multi_logloss: 0.280572\n",
      "[49]\tvalid_0's multi_logloss: 0.272539\n",
      "[50]\tvalid_0's multi_logloss: 0.264782\n",
      "[51]\tvalid_0's multi_logloss: 0.25727\n",
      "[52]\tvalid_0's multi_logloss: 0.249965\n",
      "[53]\tvalid_0's multi_logloss: 0.242922\n",
      "[54]\tvalid_0's multi_logloss: 0.235959\n",
      "[55]\tvalid_0's multi_logloss: 0.229258\n",
      "[56]\tvalid_0's multi_logloss: 0.222775\n",
      "[57]\tvalid_0's multi_logloss: 0.216454\n",
      "[58]\tvalid_0's multi_logloss: 0.210349\n",
      "[59]\tvalid_0's multi_logloss: 0.204438\n",
      "[60]\tvalid_0's multi_logloss: 0.19871\n",
      "[61]\tvalid_0's multi_logloss: 0.193175\n",
      "[62]\tvalid_0's multi_logloss: 0.187799\n",
      "[63]\tvalid_0's multi_logloss: 0.182541\n",
      "[64]\tvalid_0's multi_logloss: 0.177461\n",
      "[65]\tvalid_0's multi_logloss: 0.172557\n",
      "[66]\tvalid_0's multi_logloss: 0.167792\n",
      "[67]\tvalid_0's multi_logloss: 0.163202\n",
      "[68]\tvalid_0's multi_logloss: 0.158721\n",
      "[69]\tvalid_0's multi_logloss: 0.154433\n",
      "[70]\tvalid_0's multi_logloss: 0.150236\n",
      "[71]\tvalid_0's multi_logloss: 0.146168\n",
      "[72]\tvalid_0's multi_logloss: 0.142213\n",
      "[73]\tvalid_0's multi_logloss: 0.138393\n",
      "[74]\tvalid_0's multi_logloss: 0.134658\n",
      "[75]\tvalid_0's multi_logloss: 0.131008\n",
      "[76]\tvalid_0's multi_logloss: 0.12746\n",
      "[77]\tvalid_0's multi_logloss: 0.124023\n",
      "[78]\tvalid_0's multi_logloss: 0.120726\n",
      "[79]\tvalid_0's multi_logloss: 0.117496\n",
      "[80]\tvalid_0's multi_logloss: 0.114366\n",
      "[81]\tvalid_0's multi_logloss: 0.111298\n",
      "[82]\tvalid_0's multi_logloss: 0.108358\n",
      "[83]\tvalid_0's multi_logloss: 0.105477\n",
      "[84]\tvalid_0's multi_logloss: 0.102714\n",
      "[85]\tvalid_0's multi_logloss: 0.100049\n",
      "[86]\tvalid_0's multi_logloss: 0.0974214\n",
      "[87]\tvalid_0's multi_logloss: 0.094905\n",
      "[88]\tvalid_0's multi_logloss: 0.0924393\n",
      "[89]\tvalid_0's multi_logloss: 0.0900819\n",
      "[90]\tvalid_0's multi_logloss: 0.0877723\n",
      "[91]\tvalid_0's multi_logloss: 0.0855493\n",
      "[92]\tvalid_0's multi_logloss: 0.0833733\n",
      "[93]\tvalid_0's multi_logloss: 0.0812518\n",
      "[94]\tvalid_0's multi_logloss: 0.0792019\n",
      "[95]\tvalid_0's multi_logloss: 0.0772137\n",
      "[96]\tvalid_0's multi_logloss: 0.0752741\n",
      "[97]\tvalid_0's multi_logloss: 0.0733899\n",
      "[98]\tvalid_0's multi_logloss: 0.0715627\n",
      "[99]\tvalid_0's multi_logloss: 0.0697903\n",
      "[100]\tvalid_0's multi_logloss: 0.0680718\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.0680718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.99      1.00      0.99       327\n",
      "\n",
      "    accuracy                           1.00      1279\n",
      "   macro avg       1.00      1.00      1.00      1279\n",
      "weighted avg       1.00      1.00      1.00      1279\n",
      "\n",
      "[[336   0   0   3]\n",
      " [  0 310   0   1]\n",
      " [  0   0 302   0]\n",
      " [  0   0   0 327]]\n",
      "Accuracy: 99.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 6\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 6,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "a178f9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.32912\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.27481\n",
      "[3]\tvalid_0's multi_logloss: 1.22391\n",
      "[4]\tvalid_0's multi_logloss: 1.17606\n",
      "[5]\tvalid_0's multi_logloss: 1.13086\n",
      "[6]\tvalid_0's multi_logloss: 1.0882\n",
      "[7]\tvalid_0's multi_logloss: 1.04781\n",
      "[8]\tvalid_0's multi_logloss: 1.00934\n",
      "[9]\tvalid_0's multi_logloss: 0.972747\n",
      "[10]\tvalid_0's multi_logloss: 0.937974\n",
      "[11]\tvalid_0's multi_logloss: 0.904844\n",
      "[12]\tvalid_0's multi_logloss: 0.873187\n",
      "[13]\tvalid_0's multi_logloss: 0.842861\n",
      "[14]\tvalid_0's multi_logloss: 0.813856\n",
      "[15]\tvalid_0's multi_logloss: 0.786106\n",
      "[16]\tvalid_0's multi_logloss: 0.759531\n",
      "[17]\tvalid_0's multi_logloss: 0.734069\n",
      "[18]\tvalid_0's multi_logloss: 0.70965\n",
      "[19]\tvalid_0's multi_logloss: 0.686211\n",
      "[20]\tvalid_0's multi_logloss: 0.663701\n",
      "[21]\tvalid_0's multi_logloss: 0.642101\n",
      "[22]\tvalid_0's multi_logloss: 0.621298\n",
      "[23]\tvalid_0's multi_logloss: 0.601292\n",
      "[24]\tvalid_0's multi_logloss: 0.582037\n",
      "[25]\tvalid_0's multi_logloss: 0.563514\n",
      "[26]\tvalid_0's multi_logloss: 0.545709\n",
      "[27]\tvalid_0's multi_logloss: 0.528563\n",
      "[28]\tvalid_0's multi_logloss: 0.512046\n",
      "[29]\tvalid_0's multi_logloss: 0.49602\n",
      "[30]\tvalid_0's multi_logloss: 0.480573\n",
      "[31]\tvalid_0's multi_logloss: 0.465687\n",
      "[32]\tvalid_0's multi_logloss: 0.451314\n",
      "[33]\tvalid_0's multi_logloss: 0.437459\n",
      "[34]\tvalid_0's multi_logloss: 0.424095\n",
      "[35]\tvalid_0's multi_logloss: 0.411187\n",
      "[36]\tvalid_0's multi_logloss: 0.398727\n",
      "[37]\tvalid_0's multi_logloss: 0.386694\n",
      "[38]\tvalid_0's multi_logloss: 0.375077\n",
      "[39]\tvalid_0's multi_logloss: 0.363849\n",
      "[40]\tvalid_0's multi_logloss: 0.353006\n",
      "[41]\tvalid_0's multi_logloss: 0.342518\n",
      "[42]\tvalid_0's multi_logloss: 0.33238\n",
      "[43]\tvalid_0's multi_logloss: 0.322582\n",
      "[44]\tvalid_0's multi_logloss: 0.313045\n",
      "[45]\tvalid_0's multi_logloss: 0.303876\n",
      "[46]\tvalid_0's multi_logloss: 0.295008\n",
      "[47]\tvalid_0's multi_logloss: 0.286413\n",
      "[48]\tvalid_0's multi_logloss: 0.278059\n",
      "[49]\tvalid_0's multi_logloss: 0.270012\n",
      "[50]\tvalid_0's multi_logloss: 0.262217\n",
      "[51]\tvalid_0's multi_logloss: 0.254689\n",
      "[52]\tvalid_0's multi_logloss: 0.247324\n",
      "[53]\tvalid_0's multi_logloss: 0.240237\n",
      "[54]\tvalid_0's multi_logloss: 0.233385\n",
      "[55]\tvalid_0's multi_logloss: 0.226763\n",
      "[56]\tvalid_0's multi_logloss: 0.220287\n",
      "[57]\tvalid_0's multi_logloss: 0.214038\n",
      "[58]\tvalid_0's multi_logloss: 0.208006\n",
      "[59]\tvalid_0's multi_logloss: 0.20214\n",
      "[60]\tvalid_0's multi_logloss: 0.196411\n",
      "[61]\tvalid_0's multi_logloss: 0.190876\n",
      "[62]\tvalid_0's multi_logloss: 0.185447\n",
      "[63]\tvalid_0's multi_logloss: 0.180173\n",
      "[64]\tvalid_0's multi_logloss: 0.175067\n",
      "[65]\tvalid_0's multi_logloss: 0.170096\n",
      "[66]\tvalid_0's multi_logloss: 0.165281\n",
      "[67]\tvalid_0's multi_logloss: 0.160601\n",
      "[68]\tvalid_0's multi_logloss: 0.156114\n",
      "[69]\tvalid_0's multi_logloss: 0.151729\n",
      "[70]\tvalid_0's multi_logloss: 0.147462\n",
      "[71]\tvalid_0's multi_logloss: 0.143368\n",
      "[72]\tvalid_0's multi_logloss: 0.139361\n",
      "[73]\tvalid_0's multi_logloss: 0.135496\n",
      "[74]\tvalid_0's multi_logloss: 0.131727\n",
      "[75]\tvalid_0's multi_logloss: 0.1281\n",
      "[76]\tvalid_0's multi_logloss: 0.124566\n",
      "[77]\tvalid_0's multi_logloss: 0.121098\n",
      "[78]\tvalid_0's multi_logloss: 0.117735\n",
      "[79]\tvalid_0's multi_logloss: 0.114503\n",
      "[80]\tvalid_0's multi_logloss: 0.111342\n",
      "[81]\tvalid_0's multi_logloss: 0.108284\n",
      "[82]\tvalid_0's multi_logloss: 0.105339\n",
      "[83]\tvalid_0's multi_logloss: 0.102496\n",
      "[84]\tvalid_0's multi_logloss: 0.0996995\n",
      "[85]\tvalid_0's multi_logloss: 0.0970055\n",
      "[86]\tvalid_0's multi_logloss: 0.0943811\n",
      "[87]\tvalid_0's multi_logloss: 0.0918293\n",
      "[88]\tvalid_0's multi_logloss: 0.0893823\n",
      "[89]\tvalid_0's multi_logloss: 0.0870202\n",
      "[90]\tvalid_0's multi_logloss: 0.0847012\n",
      "[91]\tvalid_0's multi_logloss: 0.0824941\n",
      "[92]\tvalid_0's multi_logloss: 0.0803176\n",
      "[93]\tvalid_0's multi_logloss: 0.0782305\n",
      "[94]\tvalid_0's multi_logloss: 0.0762012\n",
      "[95]\tvalid_0's multi_logloss: 0.0742168\n",
      "[96]\tvalid_0's multi_logloss: 0.072295\n",
      "[97]\tvalid_0's multi_logloss: 0.0704143\n",
      "[98]\tvalid_0's multi_logloss: 0.0685828\n",
      "[99]\tvalid_0's multi_logloss: 0.0668118\n",
      "[100]\tvalid_0's multi_logloss: 0.0651231\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.0651231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.99      1.00      1.00       327\n",
      "\n",
      "    accuracy                           1.00      1279\n",
      "   macro avg       1.00      1.00      1.00      1279\n",
      "weighted avg       1.00      1.00      1.00      1279\n",
      "\n",
      "[[337   0   0   2]\n",
      " [  0 310   1   0]\n",
      " [  0   0 302   0]\n",
      " [  0   0   0 327]]\n",
      "Accuracy: 99.77%\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 7\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a27c2031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.32906\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.27469\n",
      "[3]\tvalid_0's multi_logloss: 1.22373\n",
      "[4]\tvalid_0's multi_logloss: 1.17583\n",
      "[5]\tvalid_0's multi_logloss: 1.13057\n",
      "[6]\tvalid_0's multi_logloss: 1.08786\n",
      "[7]\tvalid_0's multi_logloss: 1.04742\n",
      "[8]\tvalid_0's multi_logloss: 1.00889\n",
      "[9]\tvalid_0's multi_logloss: 0.972248\n",
      "[10]\tvalid_0's multi_logloss: 0.937428\n",
      "[11]\tvalid_0's multi_logloss: 0.904245\n",
      "[12]\tvalid_0's multi_logloss: 0.872544\n",
      "[13]\tvalid_0's multi_logloss: 0.842178\n",
      "[14]\tvalid_0's multi_logloss: 0.813169\n",
      "[15]\tvalid_0's multi_logloss: 0.785414\n",
      "[16]\tvalid_0's multi_logloss: 0.758862\n",
      "[17]\tvalid_0's multi_logloss: 0.7334\n",
      "[18]\tvalid_0's multi_logloss: 0.709\n",
      "[19]\tvalid_0's multi_logloss: 0.685597\n",
      "[20]\tvalid_0's multi_logloss: 0.663072\n",
      "[21]\tvalid_0's multi_logloss: 0.641415\n",
      "[22]\tvalid_0's multi_logloss: 0.620628\n",
      "[23]\tvalid_0's multi_logloss: 0.600592\n",
      "[24]\tvalid_0's multi_logloss: 0.581315\n",
      "[25]\tvalid_0's multi_logloss: 0.56277\n",
      "[26]\tvalid_0's multi_logloss: 0.544942\n",
      "[27]\tvalid_0's multi_logloss: 0.527771\n",
      "[28]\tvalid_0's multi_logloss: 0.511217\n",
      "[29]\tvalid_0's multi_logloss: 0.495192\n",
      "[30]\tvalid_0's multi_logloss: 0.479748\n",
      "[31]\tvalid_0's multi_logloss: 0.464855\n",
      "[32]\tvalid_0's multi_logloss: 0.450499\n",
      "[33]\tvalid_0's multi_logloss: 0.436639\n",
      "[34]\tvalid_0's multi_logloss: 0.423264\n",
      "[35]\tvalid_0's multi_logloss: 0.410366\n",
      "[36]\tvalid_0's multi_logloss: 0.397906\n",
      "[37]\tvalid_0's multi_logloss: 0.385861\n",
      "[38]\tvalid_0's multi_logloss: 0.374241\n",
      "[39]\tvalid_0's multi_logloss: 0.362996\n",
      "[40]\tvalid_0's multi_logloss: 0.352121\n",
      "[41]\tvalid_0's multi_logloss: 0.341519\n",
      "[42]\tvalid_0's multi_logloss: 0.331276\n",
      "[43]\tvalid_0's multi_logloss: 0.321453\n",
      "[44]\tvalid_0's multi_logloss: 0.31196\n",
      "[45]\tvalid_0's multi_logloss: 0.302687\n",
      "[46]\tvalid_0's multi_logloss: 0.293717\n",
      "[47]\tvalid_0's multi_logloss: 0.285062\n",
      "[48]\tvalid_0's multi_logloss: 0.276663\n",
      "[49]\tvalid_0's multi_logloss: 0.26854\n",
      "[50]\tvalid_0's multi_logloss: 0.260684\n",
      "[51]\tvalid_0's multi_logloss: 0.253076\n",
      "[52]\tvalid_0's multi_logloss: 0.245702\n",
      "[53]\tvalid_0's multi_logloss: 0.23856\n",
      "[54]\tvalid_0's multi_logloss: 0.231616\n",
      "[55]\tvalid_0's multi_logloss: 0.224905\n",
      "[56]\tvalid_0's multi_logloss: 0.218388\n",
      "[57]\tvalid_0's multi_logloss: 0.212079\n",
      "[58]\tvalid_0's multi_logloss: 0.205997\n",
      "[59]\tvalid_0's multi_logloss: 0.2001\n",
      "[60]\tvalid_0's multi_logloss: 0.194374\n",
      "[61]\tvalid_0's multi_logloss: 0.188855\n",
      "[62]\tvalid_0's multi_logloss: 0.183492\n",
      "[63]\tvalid_0's multi_logloss: 0.178209\n",
      "[64]\tvalid_0's multi_logloss: 0.173157\n",
      "[65]\tvalid_0's multi_logloss: 0.16828\n",
      "[66]\tvalid_0's multi_logloss: 0.163541\n",
      "[67]\tvalid_0's multi_logloss: 0.158961\n",
      "[68]\tvalid_0's multi_logloss: 0.154524\n",
      "[69]\tvalid_0's multi_logloss: 0.150213\n",
      "[70]\tvalid_0's multi_logloss: 0.145967\n",
      "[71]\tvalid_0's multi_logloss: 0.141869\n",
      "[72]\tvalid_0's multi_logloss: 0.137916\n",
      "[73]\tvalid_0's multi_logloss: 0.134063\n",
      "[74]\tvalid_0's multi_logloss: 0.130329\n",
      "[75]\tvalid_0's multi_logloss: 0.126689\n",
      "[76]\tvalid_0's multi_logloss: 0.12315\n",
      "[77]\tvalid_0's multi_logloss: 0.119723\n",
      "[78]\tvalid_0's multi_logloss: 0.116399\n",
      "[79]\tvalid_0's multi_logloss: 0.113163\n",
      "[80]\tvalid_0's multi_logloss: 0.110059\n",
      "[81]\tvalid_0's multi_logloss: 0.10702\n",
      "[82]\tvalid_0's multi_logloss: 0.104106\n",
      "[83]\tvalid_0's multi_logloss: 0.10125\n",
      "[84]\tvalid_0's multi_logloss: 0.0984405\n",
      "[85]\tvalid_0's multi_logloss: 0.0957901\n",
      "[86]\tvalid_0's multi_logloss: 0.0931419\n",
      "[87]\tvalid_0's multi_logloss: 0.0905802\n",
      "[88]\tvalid_0's multi_logloss: 0.0880895\n",
      "[89]\tvalid_0's multi_logloss: 0.0857391\n",
      "[90]\tvalid_0's multi_logloss: 0.0834042\n",
      "[91]\tvalid_0's multi_logloss: 0.081107\n",
      "[92]\tvalid_0's multi_logloss: 0.0788794\n",
      "[93]\tvalid_0's multi_logloss: 0.0768034\n",
      "[94]\tvalid_0's multi_logloss: 0.074705\n",
      "[95]\tvalid_0's multi_logloss: 0.0727061\n",
      "[96]\tvalid_0's multi_logloss: 0.0707818\n",
      "[97]\tvalid_0's multi_logloss: 0.0689019\n",
      "[98]\tvalid_0's multi_logloss: 0.067104\n",
      "[99]\tvalid_0's multi_logloss: 0.0653006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's multi_logloss: 0.0636194\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.0636194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.99      1.00      1.00       327\n",
      "\n",
      "    accuracy                           1.00      1279\n",
      "   macro avg       1.00      1.00      1.00      1279\n",
      "weighted avg       1.00      1.00      1.00      1279\n",
      "\n",
      "[[337   0   0   2]\n",
      " [  0 311   0   0]\n",
      " [  0   0 302   0]\n",
      " [  0   0   0 327]]\n",
      "Accuracy: 99.84%\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 8\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 8,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "a303dcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.32896\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.27448\n",
      "[3]\tvalid_0's multi_logloss: 1.22344\n",
      "[4]\tvalid_0's multi_logloss: 1.17545\n",
      "[5]\tvalid_0's multi_logloss: 1.13011\n",
      "[6]\tvalid_0's multi_logloss: 1.08732\n",
      "[7]\tvalid_0's multi_logloss: 1.04681\n",
      "[8]\tvalid_0's multi_logloss: 1.00821\n",
      "[9]\tvalid_0's multi_logloss: 0.971501\n",
      "[10]\tvalid_0's multi_logloss: 0.936623\n",
      "[11]\tvalid_0's multi_logloss: 0.903379\n",
      "[12]\tvalid_0's multi_logloss: 0.871619\n",
      "[13]\tvalid_0's multi_logloss: 0.841213\n",
      "[14]\tvalid_0's multi_logloss: 0.812144\n",
      "[15]\tvalid_0's multi_logloss: 0.784328\n",
      "[16]\tvalid_0's multi_logloss: 0.757682\n",
      "[17]\tvalid_0's multi_logloss: 0.732157\n",
      "[18]\tvalid_0's multi_logloss: 0.707671\n",
      "[19]\tvalid_0's multi_logloss: 0.68418\n",
      "[20]\tvalid_0's multi_logloss: 0.661627\n",
      "[21]\tvalid_0's multi_logloss: 0.639916\n",
      "[22]\tvalid_0's multi_logloss: 0.619047\n",
      "[23]\tvalid_0's multi_logloss: 0.599015\n",
      "[24]\tvalid_0's multi_logloss: 0.579735\n",
      "[25]\tvalid_0's multi_logloss: 0.561184\n",
      "[26]\tvalid_0's multi_logloss: 0.543357\n",
      "[27]\tvalid_0's multi_logloss: 0.52615\n",
      "[28]\tvalid_0's multi_logloss: 0.509567\n",
      "[29]\tvalid_0's multi_logloss: 0.493575\n",
      "[30]\tvalid_0's multi_logloss: 0.478168\n",
      "[31]\tvalid_0's multi_logloss: 0.463304\n",
      "[32]\tvalid_0's multi_logloss: 0.448962\n",
      "[33]\tvalid_0's multi_logloss: 0.435129\n",
      "[34]\tvalid_0's multi_logloss: 0.421771\n",
      "[35]\tvalid_0's multi_logloss: 0.408879\n",
      "[36]\tvalid_0's multi_logloss: 0.396431\n",
      "[37]\tvalid_0's multi_logloss: 0.384409\n",
      "[38]\tvalid_0's multi_logloss: 0.372798\n",
      "[39]\tvalid_0's multi_logloss: 0.361588\n",
      "[40]\tvalid_0's multi_logloss: 0.350758\n",
      "[41]\tvalid_0's multi_logloss: 0.340291\n",
      "[42]\tvalid_0's multi_logloss: 0.330165\n",
      "[43]\tvalid_0's multi_logloss: 0.320383\n",
      "[44]\tvalid_0's multi_logloss: 0.310909\n",
      "[45]\tvalid_0's multi_logloss: 0.301655\n",
      "[46]\tvalid_0's multi_logloss: 0.292716\n",
      "[47]\tvalid_0's multi_logloss: 0.28406\n",
      "[48]\tvalid_0's multi_logloss: 0.275693\n",
      "[49]\tvalid_0's multi_logloss: 0.267607\n",
      "[50]\tvalid_0's multi_logloss: 0.25979\n",
      "[51]\tvalid_0's multi_logloss: 0.252209\n",
      "[52]\tvalid_0's multi_logloss: 0.244854\n",
      "[53]\tvalid_0's multi_logloss: 0.237736\n",
      "[54]\tvalid_0's multi_logloss: 0.230845\n",
      "[55]\tvalid_0's multi_logloss: 0.224233\n",
      "[56]\tvalid_0's multi_logloss: 0.217762\n",
      "[57]\tvalid_0's multi_logloss: 0.211451\n",
      "[58]\tvalid_0's multi_logloss: 0.205379\n",
      "[59]\tvalid_0's multi_logloss: 0.199483\n",
      "[60]\tvalid_0's multi_logloss: 0.193749\n",
      "[61]\tvalid_0's multi_logloss: 0.1882\n",
      "[62]\tvalid_0's multi_logloss: 0.182855\n",
      "[63]\tvalid_0's multi_logloss: 0.177566\n",
      "[64]\tvalid_0's multi_logloss: 0.172467\n",
      "[65]\tvalid_0's multi_logloss: 0.167527\n",
      "[66]\tvalid_0's multi_logloss: 0.162725\n",
      "[67]\tvalid_0's multi_logloss: 0.158086\n",
      "[68]\tvalid_0's multi_logloss: 0.153606\n",
      "[69]\tvalid_0's multi_logloss: 0.149282\n",
      "[70]\tvalid_0's multi_logloss: 0.145061\n",
      "[71]\tvalid_0's multi_logloss: 0.140938\n",
      "[72]\tvalid_0's multi_logloss: 0.136968\n",
      "[73]\tvalid_0's multi_logloss: 0.13311\n",
      "[74]\tvalid_0's multi_logloss: 0.129356\n",
      "[75]\tvalid_0's multi_logloss: 0.125725\n",
      "[76]\tvalid_0's multi_logloss: 0.122185\n",
      "[77]\tvalid_0's multi_logloss: 0.11874\n",
      "[78]\tvalid_0's multi_logloss: 0.115396\n",
      "[79]\tvalid_0's multi_logloss: 0.112146\n",
      "[80]\tvalid_0's multi_logloss: 0.109041\n",
      "[81]\tvalid_0's multi_logloss: 0.105996\n",
      "[82]\tvalid_0's multi_logloss: 0.103046\n",
      "[83]\tvalid_0's multi_logloss: 0.100187\n",
      "[84]\tvalid_0's multi_logloss: 0.0974189\n",
      "[85]\tvalid_0's multi_logloss: 0.0947406\n",
      "[86]\tvalid_0's multi_logloss: 0.0921302\n",
      "[87]\tvalid_0's multi_logloss: 0.0896077\n",
      "[88]\tvalid_0's multi_logloss: 0.0871646\n",
      "[89]\tvalid_0's multi_logloss: 0.0847962\n",
      "[90]\tvalid_0's multi_logloss: 0.0825052\n",
      "[91]\tvalid_0's multi_logloss: 0.0803032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92]\tvalid_0's multi_logloss: 0.0781358\n",
      "[93]\tvalid_0's multi_logloss: 0.0760271\n",
      "[94]\tvalid_0's multi_logloss: 0.0739918\n",
      "[95]\tvalid_0's multi_logloss: 0.07201\n",
      "[96]\tvalid_0's multi_logloss: 0.0700924\n",
      "[97]\tvalid_0's multi_logloss: 0.0682299\n",
      "[98]\tvalid_0's multi_logloss: 0.0664326\n",
      "[99]\tvalid_0's multi_logloss: 0.0646834\n",
      "[100]\tvalid_0's multi_logloss: 0.0629887\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.0629887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.99      1.00      1.00       327\n",
      "\n",
      "    accuracy                           1.00      1279\n",
      "   macro avg       1.00      1.00      1.00      1279\n",
      "weighted avg       1.00      1.00      1.00      1279\n",
      "\n",
      "[[337   0   0   2]\n",
      " [  0 311   0   0]\n",
      " [  0   0 302   0]\n",
      " [  0   0   0 327]]\n",
      "Accuracy: 99.84%\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 9\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 9,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3521529",
   "metadata": {},
   "source": [
    "# Running differerent models, we find that the best accuracy was obtained for num_leaves = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "382ae2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.35795\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.32973\n",
      "[3]\tvalid_0's multi_logloss: 1.30241\n",
      "[4]\tvalid_0's multi_logloss: 1.27599\n",
      "[5]\tvalid_0's multi_logloss: 1.25037\n",
      "[6]\tvalid_0's multi_logloss: 1.22555\n",
      "[7]\tvalid_0's multi_logloss: 1.20145\n",
      "[8]\tvalid_0's multi_logloss: 1.17801\n",
      "[9]\tvalid_0's multi_logloss: 1.15524\n",
      "[10]\tvalid_0's multi_logloss: 1.13314\n",
      "[11]\tvalid_0's multi_logloss: 1.11164\n",
      "[12]\tvalid_0's multi_logloss: 1.09067\n",
      "[13]\tvalid_0's multi_logloss: 1.07029\n",
      "[14]\tvalid_0's multi_logloss: 1.05041\n",
      "[15]\tvalid_0's multi_logloss: 1.03101\n",
      "[16]\tvalid_0's multi_logloss: 1.01211\n",
      "[17]\tvalid_0's multi_logloss: 0.993648\n",
      "[18]\tvalid_0's multi_logloss: 0.975664\n",
      "[19]\tvalid_0's multi_logloss: 0.958113\n",
      "[20]\tvalid_0's multi_logloss: 0.940951\n",
      "[21]\tvalid_0's multi_logloss: 0.924222\n",
      "[22]\tvalid_0's multi_logloss: 0.907858\n",
      "[23]\tvalid_0's multi_logloss: 0.891867\n",
      "[24]\tvalid_0's multi_logloss: 0.876269\n",
      "[25]\tvalid_0's multi_logloss: 0.860949\n",
      "[26]\tvalid_0's multi_logloss: 0.845961\n",
      "[27]\tvalid_0's multi_logloss: 0.831299\n",
      "[28]\tvalid_0's multi_logloss: 0.816968\n",
      "[29]\tvalid_0's multi_logloss: 0.802945\n",
      "[30]\tvalid_0's multi_logloss: 0.789224\n",
      "[31]\tvalid_0's multi_logloss: 0.775792\n",
      "[32]\tvalid_0's multi_logloss: 0.762646\n",
      "[33]\tvalid_0's multi_logloss: 0.749775\n",
      "[34]\tvalid_0's multi_logloss: 0.737176\n",
      "[35]\tvalid_0's multi_logloss: 0.724826\n",
      "[36]\tvalid_0's multi_logloss: 0.71273\n",
      "[37]\tvalid_0's multi_logloss: 0.700886\n",
      "[38]\tvalid_0's multi_logloss: 0.689277\n",
      "[39]\tvalid_0's multi_logloss: 0.677893\n",
      "[40]\tvalid_0's multi_logloss: 0.666748\n",
      "[41]\tvalid_0's multi_logloss: 0.655818\n",
      "[42]\tvalid_0's multi_logloss: 0.645106\n",
      "[43]\tvalid_0's multi_logloss: 0.634586\n",
      "[44]\tvalid_0's multi_logloss: 0.624263\n",
      "[45]\tvalid_0's multi_logloss: 0.614139\n",
      "[46]\tvalid_0's multi_logloss: 0.604213\n",
      "[47]\tvalid_0's multi_logloss: 0.594474\n",
      "[48]\tvalid_0's multi_logloss: 0.584918\n",
      "[49]\tvalid_0's multi_logloss: 0.575542\n",
      "[50]\tvalid_0's multi_logloss: 0.566348\n",
      "[51]\tvalid_0's multi_logloss: 0.557338\n",
      "[52]\tvalid_0's multi_logloss: 0.548495\n",
      "[53]\tvalid_0's multi_logloss: 0.539817\n",
      "[54]\tvalid_0's multi_logloss: 0.531301\n",
      "[55]\tvalid_0's multi_logloss: 0.522938\n",
      "[56]\tvalid_0's multi_logloss: 0.514725\n",
      "[57]\tvalid_0's multi_logloss: 0.506617\n",
      "[58]\tvalid_0's multi_logloss: 0.498652\n",
      "[59]\tvalid_0's multi_logloss: 0.490834\n",
      "[60]\tvalid_0's multi_logloss: 0.483157\n",
      "[61]\tvalid_0's multi_logloss: 0.475616\n",
      "[62]\tvalid_0's multi_logloss: 0.46821\n",
      "[63]\tvalid_0's multi_logloss: 0.460938\n",
      "[64]\tvalid_0's multi_logloss: 0.453793\n",
      "[65]\tvalid_0's multi_logloss: 0.446779\n",
      "[66]\tvalid_0's multi_logloss: 0.439887\n",
      "[67]\tvalid_0's multi_logloss: 0.433119\n",
      "[68]\tvalid_0's multi_logloss: 0.426466\n",
      "[69]\tvalid_0's multi_logloss: 0.41993\n",
      "[70]\tvalid_0's multi_logloss: 0.413511\n",
      "[71]\tvalid_0's multi_logloss: 0.407199\n",
      "[72]\tvalid_0's multi_logloss: 0.400995\n",
      "[73]\tvalid_0's multi_logloss: 0.394902\n",
      "[74]\tvalid_0's multi_logloss: 0.388918\n",
      "[75]\tvalid_0's multi_logloss: 0.383032\n",
      "[76]\tvalid_0's multi_logloss: 0.377249\n",
      "[77]\tvalid_0's multi_logloss: 0.371565\n",
      "[78]\tvalid_0's multi_logloss: 0.365974\n",
      "[79]\tvalid_0's multi_logloss: 0.360477\n",
      "[80]\tvalid_0's multi_logloss: 0.355075\n",
      "[81]\tvalid_0's multi_logloss: 0.349765\n",
      "[82]\tvalid_0's multi_logloss: 0.344541\n",
      "[83]\tvalid_0's multi_logloss: 0.339405\n",
      "[84]\tvalid_0's multi_logloss: 0.334356\n",
      "[85]\tvalid_0's multi_logloss: 0.329391\n",
      "[86]\tvalid_0's multi_logloss: 0.324508\n",
      "[87]\tvalid_0's multi_logloss: 0.319704\n",
      "[88]\tvalid_0's multi_logloss: 0.314953\n",
      "[89]\tvalid_0's multi_logloss: 0.310307\n",
      "[90]\tvalid_0's multi_logloss: 0.305738\n",
      "[91]\tvalid_0's multi_logloss: 0.301244\n",
      "[92]\tvalid_0's multi_logloss: 0.296796\n",
      "[93]\tvalid_0's multi_logloss: 0.29244\n",
      "[94]\tvalid_0's multi_logloss: 0.288158\n",
      "[95]\tvalid_0's multi_logloss: 0.283948\n",
      "[96]\tvalid_0's multi_logloss: 0.279777\n",
      "[97]\tvalid_0's multi_logloss: 0.275698\n",
      "[98]\tvalid_0's multi_logloss: 0.271683\n",
      "[99]\tvalid_0's multi_logloss: 0.267738\n",
      "[100]\tvalid_0's multi_logloss: 0.263857\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.263857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.98      1.00      0.99       327\n",
      "\n",
      "    accuracy                           0.99      1279\n",
      "   macro avg       0.99      0.99      0.99      1279\n",
      "weighted avg       0.99      0.99      0.99      1279\n",
      "\n",
      "[[333   0   0   6]\n",
      " [  0 310   1   0]\n",
      " [  0   0 302   0]\n",
      " [  0   0   0 327]]\n",
      "Accuracy: 99.45%\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.01\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.01,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "6e258833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.32912\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.27481\n",
      "[3]\tvalid_0's multi_logloss: 1.22391\n",
      "[4]\tvalid_0's multi_logloss: 1.17606\n",
      "[5]\tvalid_0's multi_logloss: 1.13086\n",
      "[6]\tvalid_0's multi_logloss: 1.0882\n",
      "[7]\tvalid_0's multi_logloss: 1.04781\n",
      "[8]\tvalid_0's multi_logloss: 1.00934\n",
      "[9]\tvalid_0's multi_logloss: 0.972747\n",
      "[10]\tvalid_0's multi_logloss: 0.937974\n",
      "[11]\tvalid_0's multi_logloss: 0.904844\n",
      "[12]\tvalid_0's multi_logloss: 0.873187\n",
      "[13]\tvalid_0's multi_logloss: 0.842861\n",
      "[14]\tvalid_0's multi_logloss: 0.813856\n",
      "[15]\tvalid_0's multi_logloss: 0.786106\n",
      "[16]\tvalid_0's multi_logloss: 0.759531\n",
      "[17]\tvalid_0's multi_logloss: 0.734069\n",
      "[18]\tvalid_0's multi_logloss: 0.70965\n",
      "[19]\tvalid_0's multi_logloss: 0.686211\n",
      "[20]\tvalid_0's multi_logloss: 0.663701\n",
      "[21]\tvalid_0's multi_logloss: 0.642101\n",
      "[22]\tvalid_0's multi_logloss: 0.621298\n",
      "[23]\tvalid_0's multi_logloss: 0.601292\n",
      "[24]\tvalid_0's multi_logloss: 0.582037\n",
      "[25]\tvalid_0's multi_logloss: 0.563514\n",
      "[26]\tvalid_0's multi_logloss: 0.545709\n",
      "[27]\tvalid_0's multi_logloss: 0.528563\n",
      "[28]\tvalid_0's multi_logloss: 0.512046\n",
      "[29]\tvalid_0's multi_logloss: 0.49602\n",
      "[30]\tvalid_0's multi_logloss: 0.480573\n",
      "[31]\tvalid_0's multi_logloss: 0.465687\n",
      "[32]\tvalid_0's multi_logloss: 0.451314\n",
      "[33]\tvalid_0's multi_logloss: 0.437459\n",
      "[34]\tvalid_0's multi_logloss: 0.424095\n",
      "[35]\tvalid_0's multi_logloss: 0.411187\n",
      "[36]\tvalid_0's multi_logloss: 0.398727\n",
      "[37]\tvalid_0's multi_logloss: 0.386694\n",
      "[38]\tvalid_0's multi_logloss: 0.375077\n",
      "[39]\tvalid_0's multi_logloss: 0.363849\n",
      "[40]\tvalid_0's multi_logloss: 0.353006\n",
      "[41]\tvalid_0's multi_logloss: 0.342518\n",
      "[42]\tvalid_0's multi_logloss: 0.33238\n",
      "[43]\tvalid_0's multi_logloss: 0.322582\n",
      "[44]\tvalid_0's multi_logloss: 0.313045\n",
      "[45]\tvalid_0's multi_logloss: 0.303876\n",
      "[46]\tvalid_0's multi_logloss: 0.295008\n",
      "[47]\tvalid_0's multi_logloss: 0.286413\n",
      "[48]\tvalid_0's multi_logloss: 0.278059\n",
      "[49]\tvalid_0's multi_logloss: 0.270012\n",
      "[50]\tvalid_0's multi_logloss: 0.262217\n",
      "[51]\tvalid_0's multi_logloss: 0.254689\n",
      "[52]\tvalid_0's multi_logloss: 0.247324\n",
      "[53]\tvalid_0's multi_logloss: 0.240237\n",
      "[54]\tvalid_0's multi_logloss: 0.233385\n",
      "[55]\tvalid_0's multi_logloss: 0.226763\n",
      "[56]\tvalid_0's multi_logloss: 0.220287\n",
      "[57]\tvalid_0's multi_logloss: 0.214038\n",
      "[58]\tvalid_0's multi_logloss: 0.208006\n",
      "[59]\tvalid_0's multi_logloss: 0.20214\n",
      "[60]\tvalid_0's multi_logloss: 0.196411\n",
      "[61]\tvalid_0's multi_logloss: 0.190876\n",
      "[62]\tvalid_0's multi_logloss: 0.185447\n",
      "[63]\tvalid_0's multi_logloss: 0.180173\n",
      "[64]\tvalid_0's multi_logloss: 0.175067\n",
      "[65]\tvalid_0's multi_logloss: 0.170096\n",
      "[66]\tvalid_0's multi_logloss: 0.165281\n",
      "[67]\tvalid_0's multi_logloss: 0.160601\n",
      "[68]\tvalid_0's multi_logloss: 0.156114\n",
      "[69]\tvalid_0's multi_logloss: 0.151729\n",
      "[70]\tvalid_0's multi_logloss: 0.147462\n",
      "[71]\tvalid_0's multi_logloss: 0.143368\n",
      "[72]\tvalid_0's multi_logloss: 0.139361\n",
      "[73]\tvalid_0's multi_logloss: 0.135496\n",
      "[74]\tvalid_0's multi_logloss: 0.131727\n",
      "[75]\tvalid_0's multi_logloss: 0.1281\n",
      "[76]\tvalid_0's multi_logloss: 0.124566\n",
      "[77]\tvalid_0's multi_logloss: 0.121098\n",
      "[78]\tvalid_0's multi_logloss: 0.117735\n",
      "[79]\tvalid_0's multi_logloss: 0.114503\n",
      "[80]\tvalid_0's multi_logloss: 0.111342\n",
      "[81]\tvalid_0's multi_logloss: 0.108284\n",
      "[82]\tvalid_0's multi_logloss: 0.105339\n",
      "[83]\tvalid_0's multi_logloss: 0.102496\n",
      "[84]\tvalid_0's multi_logloss: 0.0996995\n",
      "[85]\tvalid_0's multi_logloss: 0.0970055\n",
      "[86]\tvalid_0's multi_logloss: 0.0943811\n",
      "[87]\tvalid_0's multi_logloss: 0.0918293\n",
      "[88]\tvalid_0's multi_logloss: 0.0893823\n",
      "[89]\tvalid_0's multi_logloss: 0.0870202\n",
      "[90]\tvalid_0's multi_logloss: 0.0847012\n",
      "[91]\tvalid_0's multi_logloss: 0.0824941\n",
      "[92]\tvalid_0's multi_logloss: 0.0803176\n",
      "[93]\tvalid_0's multi_logloss: 0.0782305\n",
      "[94]\tvalid_0's multi_logloss: 0.0762012\n",
      "[95]\tvalid_0's multi_logloss: 0.0742168\n",
      "[96]\tvalid_0's multi_logloss: 0.072295\n",
      "[97]\tvalid_0's multi_logloss: 0.0704143\n",
      "[98]\tvalid_0's multi_logloss: 0.0685828\n",
      "[99]\tvalid_0's multi_logloss: 0.0668118\n",
      "[100]\tvalid_0's multi_logloss: 0.0651231\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.0651231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.99      1.00      1.00       327\n",
      "\n",
      "    accuracy                           1.00      1279\n",
      "   macro avg       1.00      1.00      1.00      1279\n",
      "weighted avg       1.00      1.00      1.00      1279\n",
      "\n",
      "[[337   0   0   2]\n",
      " [  0 310   1   0]\n",
      " [  0   0 302   0]\n",
      " [  0   0   0 327]]\n",
      "Accuracy: 99.77%\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.02\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "1561d112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.30059\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.22233\n",
      "[3]\tvalid_0's multi_logloss: 1.15099\n",
      "[4]\tvalid_0's multi_logloss: 1.08574\n",
      "[5]\tvalid_0's multi_logloss: 1.02553\n",
      "[6]\tvalid_0's multi_logloss: 0.969881\n",
      "[7]\tvalid_0's multi_logloss: 0.91823\n",
      "[8]\tvalid_0's multi_logloss: 0.870108\n",
      "[9]\tvalid_0's multi_logloss: 0.825089\n",
      "[10]\tvalid_0's multi_logloss: 0.782987\n",
      "[11]\tvalid_0's multi_logloss: 0.743557\n",
      "[12]\tvalid_0's multi_logloss: 0.706572\n",
      "[13]\tvalid_0's multi_logloss: 0.671811\n",
      "[14]\tvalid_0's multi_logloss: 0.639129\n",
      "[15]\tvalid_0's multi_logloss: 0.608294\n",
      "[16]\tvalid_0's multi_logloss: 0.579203\n",
      "[17]\tvalid_0's multi_logloss: 0.551743\n",
      "[18]\tvalid_0's multi_logloss: 0.525847\n",
      "[19]\tvalid_0's multi_logloss: 0.501369\n",
      "[20]\tvalid_0's multi_logloss: 0.47806\n",
      "[21]\tvalid_0's multi_logloss: 0.455994\n",
      "[22]\tvalid_0's multi_logloss: 0.4351\n",
      "[23]\tvalid_0's multi_logloss: 0.415299\n",
      "[24]\tvalid_0's multi_logloss: 0.396513\n",
      "[25]\tvalid_0's multi_logloss: 0.378705\n",
      "[26]\tvalid_0's multi_logloss: 0.361788\n",
      "[27]\tvalid_0's multi_logloss: 0.345721\n",
      "[28]\tvalid_0's multi_logloss: 0.330459\n",
      "[29]\tvalid_0's multi_logloss: 0.31595\n",
      "[30]\tvalid_0's multi_logloss: 0.302146\n",
      "[31]\tvalid_0's multi_logloss: 0.288995\n",
      "[32]\tvalid_0's multi_logloss: 0.276505\n",
      "[33]\tvalid_0's multi_logloss: 0.264522\n",
      "[34]\tvalid_0's multi_logloss: 0.253173\n",
      "[35]\tvalid_0's multi_logloss: 0.242346\n",
      "[36]\tvalid_0's multi_logloss: 0.232036\n",
      "[37]\tvalid_0's multi_logloss: 0.222135\n",
      "[38]\tvalid_0's multi_logloss: 0.212761\n",
      "[39]\tvalid_0's multi_logloss: 0.203798\n",
      "[40]\tvalid_0's multi_logloss: 0.195187\n",
      "[41]\tvalid_0's multi_logloss: 0.18689\n",
      "[42]\tvalid_0's multi_logloss: 0.178988\n",
      "[43]\tvalid_0's multi_logloss: 0.171437\n",
      "[44]\tvalid_0's multi_logloss: 0.16418\n",
      "[45]\tvalid_0's multi_logloss: 0.157301\n",
      "[46]\tvalid_0's multi_logloss: 0.150693\n",
      "[47]\tvalid_0's multi_logloss: 0.144444\n",
      "[48]\tvalid_0's multi_logloss: 0.138443\n",
      "[49]\tvalid_0's multi_logloss: 0.132686\n",
      "[50]\tvalid_0's multi_logloss: 0.127231\n",
      "[51]\tvalid_0's multi_logloss: 0.121988\n",
      "[52]\tvalid_0's multi_logloss: 0.11694\n",
      "[53]\tvalid_0's multi_logloss: 0.112163\n",
      "[54]\tvalid_0's multi_logloss: 0.107572\n",
      "[55]\tvalid_0's multi_logloss: 0.103239\n",
      "[56]\tvalid_0's multi_logloss: 0.099042\n",
      "[57]\tvalid_0's multi_logloss: 0.0950735\n",
      "[58]\tvalid_0's multi_logloss: 0.0912529\n",
      "[59]\tvalid_0's multi_logloss: 0.0876501\n",
      "[60]\tvalid_0's multi_logloss: 0.0841575\n",
      "[61]\tvalid_0's multi_logloss: 0.0808759\n",
      "[62]\tvalid_0's multi_logloss: 0.0777431\n",
      "[63]\tvalid_0's multi_logloss: 0.0747241\n",
      "[64]\tvalid_0's multi_logloss: 0.0718023\n",
      "[65]\tvalid_0's multi_logloss: 0.0690128\n",
      "[66]\tvalid_0's multi_logloss: 0.0663879\n",
      "[67]\tvalid_0's multi_logloss: 0.0638926\n",
      "[68]\tvalid_0's multi_logloss: 0.0614351\n",
      "[69]\tvalid_0's multi_logloss: 0.0591266\n",
      "[70]\tvalid_0's multi_logloss: 0.0569233\n",
      "[71]\tvalid_0's multi_logloss: 0.0548245\n",
      "[72]\tvalid_0's multi_logloss: 0.0528119\n",
      "[73]\tvalid_0's multi_logloss: 0.0508276\n",
      "[74]\tvalid_0's multi_logloss: 0.0489327\n",
      "[75]\tvalid_0's multi_logloss: 0.0471236\n",
      "[76]\tvalid_0's multi_logloss: 0.0453887\n",
      "[77]\tvalid_0's multi_logloss: 0.0436884\n",
      "[78]\tvalid_0's multi_logloss: 0.0421051\n",
      "[79]\tvalid_0's multi_logloss: 0.0405462\n",
      "[80]\tvalid_0's multi_logloss: 0.0390794\n",
      "[81]\tvalid_0's multi_logloss: 0.0376747\n",
      "[82]\tvalid_0's multi_logloss: 0.0363469\n",
      "[83]\tvalid_0's multi_logloss: 0.0350767\n",
      "[84]\tvalid_0's multi_logloss: 0.0339124\n",
      "[85]\tvalid_0's multi_logloss: 0.0327747\n",
      "[86]\tvalid_0's multi_logloss: 0.0316627\n",
      "[87]\tvalid_0's multi_logloss: 0.0305715\n",
      "[88]\tvalid_0's multi_logloss: 0.0295421\n",
      "[89]\tvalid_0's multi_logloss: 0.0285291\n",
      "[90]\tvalid_0's multi_logloss: 0.0275753\n",
      "[91]\tvalid_0's multi_logloss: 0.0266851\n",
      "[92]\tvalid_0's multi_logloss: 0.0257931\n",
      "[93]\tvalid_0's multi_logloss: 0.0249419\n",
      "[94]\tvalid_0's multi_logloss: 0.0241781\n",
      "[95]\tvalid_0's multi_logloss: 0.0234329\n",
      "[96]\tvalid_0's multi_logloss: 0.0226857\n",
      "[97]\tvalid_0's multi_logloss: 0.0220198\n",
      "[98]\tvalid_0's multi_logloss: 0.0213571\n",
      "[99]\tvalid_0's multi_logloss: 0.0207363\n",
      "[100]\tvalid_0's multi_logloss: 0.0201334\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.0201334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.99      1.00      1.00       327\n",
      "\n",
      "    accuracy                           1.00      1279\n",
      "   macro avg       1.00      1.00      1.00      1279\n",
      "weighted avg       1.00      1.00      1.00      1279\n",
      "\n",
      "[[337   0   0   2]\n",
      " [  0 310   1   0]\n",
      " [  0   0 302   0]\n",
      " [  0   0   0 327]]\n",
      "Accuracy: 99.77%\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.03\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.03,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "91c1f935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.27238\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.17196\n",
      "[3]\tvalid_0's multi_logloss: 1.08305\n",
      "[4]\tvalid_0's multi_logloss: 1.00359\n",
      "[5]\tvalid_0's multi_logloss: 0.931839\n",
      "[6]\tvalid_0's multi_logloss: 0.866892\n",
      "[7]\tvalid_0's multi_logloss: 0.807509\n",
      "[8]\tvalid_0's multi_logloss: 0.753193\n",
      "[9]\tvalid_0's multi_logloss: 0.703393\n",
      "[10]\tvalid_0's multi_logloss: 0.657567\n",
      "[11]\tvalid_0's multi_logloss: 0.615369\n",
      "[12]\tvalid_0's multi_logloss: 0.576285\n",
      "[13]\tvalid_0's multi_logloss: 0.540116\n",
      "[14]\tvalid_0's multi_logloss: 0.506647\n",
      "[15]\tvalid_0's multi_logloss: 0.475376\n",
      "[16]\tvalid_0's multi_logloss: 0.44633\n",
      "[17]\tvalid_0's multi_logloss: 0.419317\n",
      "[18]\tvalid_0's multi_logloss: 0.394154\n",
      "[19]\tvalid_0's multi_logloss: 0.370716\n",
      "[20]\tvalid_0's multi_logloss: 0.348848\n",
      "[21]\tvalid_0's multi_logloss: 0.32842\n",
      "[22]\tvalid_0's multi_logloss: 0.309336\n",
      "[23]\tvalid_0's multi_logloss: 0.291482\n",
      "[24]\tvalid_0's multi_logloss: 0.274643\n",
      "[25]\tvalid_0's multi_logloss: 0.259006\n",
      "[26]\tvalid_0's multi_logloss: 0.244348\n",
      "[27]\tvalid_0's multi_logloss: 0.230565\n",
      "[28]\tvalid_0's multi_logloss: 0.217544\n",
      "[29]\tvalid_0's multi_logloss: 0.205383\n",
      "[30]\tvalid_0's multi_logloss: 0.193965\n",
      "[31]\tvalid_0's multi_logloss: 0.183042\n",
      "[32]\tvalid_0's multi_logloss: 0.172773\n",
      "[33]\tvalid_0's multi_logloss: 0.163175\n",
      "[34]\tvalid_0's multi_logloss: 0.154061\n",
      "[35]\tvalid_0's multi_logloss: 0.145572\n",
      "[36]\tvalid_0's multi_logloss: 0.137528\n",
      "[37]\tvalid_0's multi_logloss: 0.129978\n",
      "[38]\tvalid_0's multi_logloss: 0.122862\n",
      "[39]\tvalid_0's multi_logloss: 0.11612\n",
      "[40]\tvalid_0's multi_logloss: 0.109835\n",
      "[41]\tvalid_0's multi_logloss: 0.103877\n",
      "[42]\tvalid_0's multi_logloss: 0.0983521\n",
      "[43]\tvalid_0's multi_logloss: 0.0931318\n",
      "[44]\tvalid_0's multi_logloss: 0.0881998\n",
      "[45]\tvalid_0's multi_logloss: 0.0836038\n",
      "[46]\tvalid_0's multi_logloss: 0.0792521\n",
      "[47]\tvalid_0's multi_logloss: 0.0752079\n",
      "[48]\tvalid_0's multi_logloss: 0.071335\n",
      "[49]\tvalid_0's multi_logloss: 0.0676673\n",
      "[50]\tvalid_0's multi_logloss: 0.0642835\n",
      "[51]\tvalid_0's multi_logloss: 0.0610046\n",
      "[52]\tvalid_0's multi_logloss: 0.0579986\n",
      "[53]\tvalid_0's multi_logloss: 0.0551723\n",
      "[54]\tvalid_0's multi_logloss: 0.0524849\n",
      "[55]\tvalid_0's multi_logloss: 0.049814\n",
      "[56]\tvalid_0's multi_logloss: 0.0473589\n",
      "[57]\tvalid_0's multi_logloss: 0.0449904\n",
      "[58]\tvalid_0's multi_logloss: 0.0427963\n",
      "[59]\tvalid_0's multi_logloss: 0.0406671\n",
      "[60]\tvalid_0's multi_logloss: 0.0387805\n",
      "[61]\tvalid_0's multi_logloss: 0.0369377\n",
      "[62]\tvalid_0's multi_logloss: 0.0352161\n",
      "[63]\tvalid_0's multi_logloss: 0.0336476\n",
      "[64]\tvalid_0's multi_logloss: 0.0321182\n",
      "[65]\tvalid_0's multi_logloss: 0.0307075\n",
      "[66]\tvalid_0's multi_logloss: 0.0293942\n",
      "[67]\tvalid_0's multi_logloss: 0.0281078\n",
      "[68]\tvalid_0's multi_logloss: 0.026896\n",
      "[69]\tvalid_0's multi_logloss: 0.0257078\n",
      "[70]\tvalid_0's multi_logloss: 0.0246138\n",
      "[71]\tvalid_0's multi_logloss: 0.0235602\n",
      "[72]\tvalid_0's multi_logloss: 0.0225859\n",
      "[73]\tvalid_0's multi_logloss: 0.0217014\n",
      "[74]\tvalid_0's multi_logloss: 0.0208862\n",
      "[75]\tvalid_0's multi_logloss: 0.0201227\n",
      "[76]\tvalid_0's multi_logloss: 0.01941\n",
      "[77]\tvalid_0's multi_logloss: 0.018745\n",
      "[78]\tvalid_0's multi_logloss: 0.0180814\n",
      "[79]\tvalid_0's multi_logloss: 0.0174945\n",
      "[80]\tvalid_0's multi_logloss: 0.0169452\n",
      "[81]\tvalid_0's multi_logloss: 0.016436\n",
      "[82]\tvalid_0's multi_logloss: 0.0159414\n",
      "[83]\tvalid_0's multi_logloss: 0.0154926\n",
      "[84]\tvalid_0's multi_logloss: 0.0150678\n",
      "[85]\tvalid_0's multi_logloss: 0.014621\n",
      "[86]\tvalid_0's multi_logloss: 0.0142403\n",
      "[87]\tvalid_0's multi_logloss: 0.0138366\n",
      "[88]\tvalid_0's multi_logloss: 0.013379\n",
      "[89]\tvalid_0's multi_logloss: 0.0130011\n",
      "[90]\tvalid_0's multi_logloss: 0.0126405\n",
      "[91]\tvalid_0's multi_logloss: 0.0122934\n",
      "[92]\tvalid_0's multi_logloss: 0.0119424\n",
      "[93]\tvalid_0's multi_logloss: 0.0116038\n",
      "[94]\tvalid_0's multi_logloss: 0.0112647\n",
      "[95]\tvalid_0's multi_logloss: 0.0109488\n",
      "[96]\tvalid_0's multi_logloss: 0.0106879\n",
      "[97]\tvalid_0's multi_logloss: 0.0103992\n",
      "[98]\tvalid_0's multi_logloss: 0.0101701\n",
      "[99]\tvalid_0's multi_logloss: 0.0099136\n",
      "[100]\tvalid_0's multi_logloss: 0.00967445\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.00967445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.99      1.00      1.00       327\n",
      "\n",
      "    accuracy                           1.00      1279\n",
      "   macro avg       1.00      1.00      1.00      1279\n",
      "weighted avg       1.00      1.00      1.00      1279\n",
      "\n",
      "[[337   0   0   2]\n",
      " [  0 311   0   0]\n",
      " [  0   0 302   0]\n",
      " [  0   0   0 327]]\n",
      "Accuracy: 99.84%\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.04\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.04,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "71999eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.24448\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.12371\n",
      "[3]\tvalid_0's multi_logloss: 1.01962\n",
      "[4]\tvalid_0's multi_logloss: 0.928671\n",
      "[5]\tvalid_0's multi_logloss: 0.848212\n",
      "[6]\tvalid_0's multi_logloss: 0.776387\n",
      "[7]\tvalid_0's multi_logloss: 0.712134\n",
      "[8]\tvalid_0's multi_logloss: 0.654342\n",
      "[9]\tvalid_0's multi_logloss: 0.602131\n",
      "[10]\tvalid_0's multi_logloss: 0.554824\n",
      "[11]\tvalid_0's multi_logloss: 0.511937\n",
      "[12]\tvalid_0's multi_logloss: 0.47264\n",
      "[13]\tvalid_0's multi_logloss: 0.436806\n",
      "[14]\tvalid_0's multi_logloss: 0.404098\n",
      "[15]\tvalid_0's multi_logloss: 0.374153\n",
      "[16]\tvalid_0's multi_logloss: 0.346723\n",
      "[17]\tvalid_0's multi_logloss: 0.321534\n",
      "[18]\tvalid_0's multi_logloss: 0.298385\n",
      "[19]\tvalid_0's multi_logloss: 0.276963\n",
      "[20]\tvalid_0's multi_logloss: 0.25733\n",
      "[21]\tvalid_0's multi_logloss: 0.239261\n",
      "[22]\tvalid_0's multi_logloss: 0.222545\n",
      "[23]\tvalid_0's multi_logloss: 0.207063\n",
      "[24]\tvalid_0's multi_logloss: 0.192693\n",
      "[25]\tvalid_0's multi_logloss: 0.179258\n",
      "[26]\tvalid_0's multi_logloss: 0.166822\n",
      "[27]\tvalid_0's multi_logloss: 0.155244\n",
      "[28]\tvalid_0's multi_logloss: 0.144643\n",
      "[29]\tvalid_0's multi_logloss: 0.134773\n",
      "[30]\tvalid_0's multi_logloss: 0.125579\n",
      "[31]\tvalid_0's multi_logloss: 0.117081\n",
      "[32]\tvalid_0's multi_logloss: 0.109214\n",
      "[33]\tvalid_0's multi_logloss: 0.101845\n",
      "[34]\tvalid_0's multi_logloss: 0.0950408\n",
      "[35]\tvalid_0's multi_logloss: 0.0888148\n",
      "[36]\tvalid_0's multi_logloss: 0.0829634\n",
      "[37]\tvalid_0's multi_logloss: 0.0776816\n",
      "[38]\tvalid_0's multi_logloss: 0.0727197\n",
      "[39]\tvalid_0's multi_logloss: 0.068151\n",
      "[40]\tvalid_0's multi_logloss: 0.063829\n",
      "[41]\tvalid_0's multi_logloss: 0.0598591\n",
      "[42]\tvalid_0's multi_logloss: 0.0561838\n",
      "[43]\tvalid_0's multi_logloss: 0.0527763\n",
      "[44]\tvalid_0's multi_logloss: 0.0496301\n",
      "[45]\tvalid_0's multi_logloss: 0.0465988\n",
      "[46]\tvalid_0's multi_logloss: 0.0437205\n",
      "[47]\tvalid_0's multi_logloss: 0.041116\n",
      "[48]\tvalid_0's multi_logloss: 0.0386325\n",
      "[49]\tvalid_0's multi_logloss: 0.0363619\n",
      "[50]\tvalid_0's multi_logloss: 0.0343274\n",
      "[51]\tvalid_0's multi_logloss: 0.0323841\n",
      "[52]\tvalid_0's multi_logloss: 0.0306262\n",
      "[53]\tvalid_0's multi_logloss: 0.0290084\n",
      "[54]\tvalid_0's multi_logloss: 0.0273819\n",
      "[55]\tvalid_0's multi_logloss: 0.0258891\n",
      "[56]\tvalid_0's multi_logloss: 0.0245105\n",
      "[57]\tvalid_0's multi_logloss: 0.0232071\n",
      "[58]\tvalid_0's multi_logloss: 0.0220254\n",
      "[59]\tvalid_0's multi_logloss: 0.0209275\n",
      "[60]\tvalid_0's multi_logloss: 0.019924\n",
      "[61]\tvalid_0's multi_logloss: 0.0189839\n",
      "[62]\tvalid_0's multi_logloss: 0.0181699\n",
      "[63]\tvalid_0's multi_logloss: 0.0174184\n",
      "[64]\tvalid_0's multi_logloss: 0.0167326\n",
      "[65]\tvalid_0's multi_logloss: 0.0161002\n",
      "[66]\tvalid_0's multi_logloss: 0.01551\n",
      "[67]\tvalid_0's multi_logloss: 0.0149585\n",
      "[68]\tvalid_0's multi_logloss: 0.0144564\n",
      "[69]\tvalid_0's multi_logloss: 0.0139973\n",
      "[70]\tvalid_0's multi_logloss: 0.0135098\n",
      "[71]\tvalid_0's multi_logloss: 0.0129647\n",
      "[72]\tvalid_0's multi_logloss: 0.0125264\n",
      "[73]\tvalid_0's multi_logloss: 0.0121452\n",
      "[74]\tvalid_0's multi_logloss: 0.0117725\n",
      "[75]\tvalid_0's multi_logloss: 0.0113902\n",
      "[76]\tvalid_0's multi_logloss: 0.0110357\n",
      "[77]\tvalid_0's multi_logloss: 0.0107224\n",
      "[78]\tvalid_0's multi_logloss: 0.0103933\n",
      "[79]\tvalid_0's multi_logloss: 0.0101137\n",
      "[80]\tvalid_0's multi_logloss: 0.00980679\n",
      "[81]\tvalid_0's multi_logloss: 0.00951936\n",
      "[82]\tvalid_0's multi_logloss: 0.00931984\n",
      "[83]\tvalid_0's multi_logloss: 0.00920418\n",
      "[84]\tvalid_0's multi_logloss: 0.00905557\n",
      "[85]\tvalid_0's multi_logloss: 0.00891969\n",
      "[86]\tvalid_0's multi_logloss: 0.00876756\n",
      "[87]\tvalid_0's multi_logloss: 0.00871151\n",
      "[88]\tvalid_0's multi_logloss: 0.0085867\n",
      "[89]\tvalid_0's multi_logloss: 0.00854114\n",
      "[90]\tvalid_0's multi_logloss: 0.00846305\n",
      "[91]\tvalid_0's multi_logloss: 0.00841812\n",
      "[92]\tvalid_0's multi_logloss: 0.00831584\n",
      "[93]\tvalid_0's multi_logloss: 0.00830949\n",
      "[94]\tvalid_0's multi_logloss: 0.00818875\n",
      "[95]\tvalid_0's multi_logloss: 0.00818672\n",
      "[96]\tvalid_0's multi_logloss: 0.00818054\n",
      "[97]\tvalid_0's multi_logloss: 0.00813723\n",
      "[98]\tvalid_0's multi_logloss: 0.00811418\n",
      "[99]\tvalid_0's multi_logloss: 0.00808058\n",
      "[100]\tvalid_0's multi_logloss: 0.00806828\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.00806828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.99      1.00      1.00       327\n",
      "\n",
      "    accuracy                           1.00      1279\n",
      "   macro avg       1.00      1.00      1.00      1279\n",
      "weighted avg       1.00      1.00      1.00      1279\n",
      "\n",
      "[[337   0   0   2]\n",
      " [  0 311   0   0]\n",
      " [  0   0 302   0]\n",
      " [  0   0   0 327]]\n",
      "Accuracy: 99.84%\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.05\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "823d5dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.16272\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.990823\n",
      "[3]\tvalid_0's multi_logloss: 0.852919\n",
      "[4]\tvalid_0's multi_logloss: 0.739257\n",
      "[5]\tvalid_0's multi_logloss: 0.644211\n",
      "[6]\tvalid_0's multi_logloss: 0.56376\n",
      "[7]\tvalid_0's multi_logloss: 0.495138\n",
      "[8]\tvalid_0's multi_logloss: 0.435813\n",
      "[9]\tvalid_0's multi_logloss: 0.384561\n",
      "[10]\tvalid_0's multi_logloss: 0.340141\n",
      "[11]\tvalid_0's multi_logloss: 0.301455\n",
      "[12]\tvalid_0's multi_logloss: 0.267667\n",
      "[13]\tvalid_0's multi_logloss: 0.237815\n",
      "[14]\tvalid_0's multi_logloss: 0.211743\n",
      "[15]\tvalid_0's multi_logloss: 0.1888\n",
      "[16]\tvalid_0's multi_logloss: 0.168148\n",
      "[17]\tvalid_0's multi_logloss: 0.149889\n",
      "[18]\tvalid_0's multi_logloss: 0.13386\n",
      "[19]\tvalid_0's multi_logloss: 0.119476\n",
      "[20]\tvalid_0's multi_logloss: 0.106914\n",
      "[21]\tvalid_0's multi_logloss: 0.0956691\n",
      "[22]\tvalid_0's multi_logloss: 0.0858212\n",
      "[23]\tvalid_0's multi_logloss: 0.0770252\n",
      "[24]\tvalid_0's multi_logloss: 0.0692584\n",
      "[25]\tvalid_0's multi_logloss: 0.0625109\n",
      "[26]\tvalid_0's multi_logloss: 0.0563162\n",
      "[27]\tvalid_0's multi_logloss: 0.0509511\n",
      "[28]\tvalid_0's multi_logloss: 0.0460176\n",
      "[29]\tvalid_0's multi_logloss: 0.0416018\n",
      "[30]\tvalid_0's multi_logloss: 0.0377296\n",
      "[31]\tvalid_0's multi_logloss: 0.0341782\n",
      "[32]\tvalid_0's multi_logloss: 0.031066\n",
      "[33]\tvalid_0's multi_logloss: 0.0283567\n",
      "[34]\tvalid_0's multi_logloss: 0.0259458\n",
      "[35]\tvalid_0's multi_logloss: 0.0237537\n",
      "[36]\tvalid_0's multi_logloss: 0.0218626\n",
      "[37]\tvalid_0's multi_logloss: 0.0201315\n",
      "[38]\tvalid_0's multi_logloss: 0.018689\n",
      "[39]\tvalid_0's multi_logloss: 0.0174427\n",
      "[40]\tvalid_0's multi_logloss: 0.016358\n",
      "[41]\tvalid_0's multi_logloss: 0.0154245\n",
      "[42]\tvalid_0's multi_logloss: 0.0145958\n",
      "[43]\tvalid_0's multi_logloss: 0.0138888\n",
      "[44]\tvalid_0's multi_logloss: 0.0132451\n",
      "[45]\tvalid_0's multi_logloss: 0.0126074\n",
      "[46]\tvalid_0's multi_logloss: 0.0119577\n",
      "[47]\tvalid_0's multi_logloss: 0.0112813\n",
      "[48]\tvalid_0's multi_logloss: 0.0108573\n",
      "[49]\tvalid_0's multi_logloss: 0.0104926\n",
      "[50]\tvalid_0's multi_logloss: 0.0100943\n",
      "[51]\tvalid_0's multi_logloss: 0.00969708\n",
      "[52]\tvalid_0's multi_logloss: 0.00942169\n",
      "[53]\tvalid_0's multi_logloss: 0.00912221\n",
      "[54]\tvalid_0's multi_logloss: 0.00892892\n",
      "[55]\tvalid_0's multi_logloss: 0.00883446\n",
      "[56]\tvalid_0's multi_logloss: 0.00860749\n",
      "[57]\tvalid_0's multi_logloss: 0.00849972\n",
      "[58]\tvalid_0's multi_logloss: 0.00848219\n",
      "[59]\tvalid_0's multi_logloss: 0.00848718\n",
      "[60]\tvalid_0's multi_logloss: 0.0083093\n",
      "[61]\tvalid_0's multi_logloss: 0.00833059\n",
      "[62]\tvalid_0's multi_logloss: 0.00830419\n",
      "[63]\tvalid_0's multi_logloss: 0.00833148\n",
      "[64]\tvalid_0's multi_logloss: 0.00827111\n",
      "[65]\tvalid_0's multi_logloss: 0.00824275\n",
      "[66]\tvalid_0's multi_logloss: 0.00830878\n",
      "[67]\tvalid_0's multi_logloss: 0.00814803\n",
      "[68]\tvalid_0's multi_logloss: 0.00821707\n",
      "[69]\tvalid_0's multi_logloss: 0.00821606\n",
      "[70]\tvalid_0's multi_logloss: 0.0083267\n",
      "[71]\tvalid_0's multi_logloss: 0.00830855\n",
      "[72]\tvalid_0's multi_logloss: 0.00841185\n",
      "[73]\tvalid_0's multi_logloss: 0.00850247\n",
      "[74]\tvalid_0's multi_logloss: 0.00837862\n",
      "[75]\tvalid_0's multi_logloss: 0.00850828\n",
      "[76]\tvalid_0's multi_logloss: 0.00848833\n",
      "[77]\tvalid_0's multi_logloss: 0.00843148\n",
      "[78]\tvalid_0's multi_logloss: 0.00843105\n",
      "[79]\tvalid_0's multi_logloss: 0.00855196\n",
      "[80]\tvalid_0's multi_logloss: 0.00858033\n",
      "[81]\tvalid_0's multi_logloss: 0.00860576\n",
      "[82]\tvalid_0's multi_logloss: 0.00868653\n",
      "[83]\tvalid_0's multi_logloss: 0.0088041\n",
      "[84]\tvalid_0's multi_logloss: 0.00885436\n",
      "[85]\tvalid_0's multi_logloss: 0.00896051\n",
      "[86]\tvalid_0's multi_logloss: 0.00898996\n",
      "[87]\tvalid_0's multi_logloss: 0.00898716\n",
      "[88]\tvalid_0's multi_logloss: 0.00898883\n",
      "[89]\tvalid_0's multi_logloss: 0.00884886\n",
      "[90]\tvalid_0's multi_logloss: 0.00891767\n",
      "[91]\tvalid_0's multi_logloss: 0.00904113\n",
      "[92]\tvalid_0's multi_logloss: 0.00908398\n",
      "[93]\tvalid_0's multi_logloss: 0.00923008\n",
      "[94]\tvalid_0's multi_logloss: 0.0090904\n",
      "[95]\tvalid_0's multi_logloss: 0.00908763\n",
      "[96]\tvalid_0's multi_logloss: 0.00919426\n",
      "[97]\tvalid_0's multi_logloss: 0.00927\n",
      "[98]\tvalid_0's multi_logloss: 0.00930526\n",
      "[99]\tvalid_0's multi_logloss: 0.00932043\n",
      "[100]\tvalid_0's multi_logloss: 0.00931896\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[67]\tvalid_0's multi_logloss: 0.00814803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.99      1.00      1.00       327\n",
      "\n",
      "    accuracy                           1.00      1279\n",
      "   macro avg       1.00      1.00      1.00      1279\n",
      "weighted avg       1.00      1.00      1.00      1279\n",
      "\n",
      "[[337   0   0   2]\n",
      " [  0 311   0   0]\n",
      " [  0   0 302   0]\n",
      " [  0   0   0 327]]\n",
      "Accuracy: 99.84%\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.08\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.08,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "9e652265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.38122\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.3754\n",
      "[3]\tvalid_0's multi_logloss: 1.36962\n",
      "[4]\tvalid_0's multi_logloss: 1.36389\n",
      "[5]\tvalid_0's multi_logloss: 1.35819\n",
      "[6]\tvalid_0's multi_logloss: 1.35253\n",
      "[7]\tvalid_0's multi_logloss: 1.3469\n",
      "[8]\tvalid_0's multi_logloss: 1.34131\n",
      "[9]\tvalid_0's multi_logloss: 1.33576\n",
      "[10]\tvalid_0's multi_logloss: 1.33023\n",
      "[11]\tvalid_0's multi_logloss: 1.32474\n",
      "[12]\tvalid_0's multi_logloss: 1.3193\n",
      "[13]\tvalid_0's multi_logloss: 1.31388\n",
      "[14]\tvalid_0's multi_logloss: 1.3085\n",
      "[15]\tvalid_0's multi_logloss: 1.30316\n",
      "[16]\tvalid_0's multi_logloss: 1.29784\n",
      "[17]\tvalid_0's multi_logloss: 1.29257\n",
      "[18]\tvalid_0's multi_logloss: 1.28732\n",
      "[19]\tvalid_0's multi_logloss: 1.28211\n",
      "[20]\tvalid_0's multi_logloss: 1.27693\n",
      "[21]\tvalid_0's multi_logloss: 1.27178\n",
      "[22]\tvalid_0's multi_logloss: 1.26667\n",
      "[23]\tvalid_0's multi_logloss: 1.26159\n",
      "[24]\tvalid_0's multi_logloss: 1.25653\n",
      "[25]\tvalid_0's multi_logloss: 1.25151\n",
      "[26]\tvalid_0's multi_logloss: 1.24651\n",
      "[27]\tvalid_0's multi_logloss: 1.24154\n",
      "[28]\tvalid_0's multi_logloss: 1.23661\n",
      "[29]\tvalid_0's multi_logloss: 1.2317\n",
      "[30]\tvalid_0's multi_logloss: 1.22682\n",
      "[31]\tvalid_0's multi_logloss: 1.22198\n",
      "[32]\tvalid_0's multi_logloss: 1.21715\n",
      "[33]\tvalid_0's multi_logloss: 1.21236\n",
      "[34]\tvalid_0's multi_logloss: 1.20759\n",
      "[35]\tvalid_0's multi_logloss: 1.20285\n",
      "[36]\tvalid_0's multi_logloss: 1.19814\n",
      "[37]\tvalid_0's multi_logloss: 1.19345\n",
      "[38]\tvalid_0's multi_logloss: 1.1888\n",
      "[39]\tvalid_0's multi_logloss: 1.18417\n",
      "[40]\tvalid_0's multi_logloss: 1.17956\n",
      "[41]\tvalid_0's multi_logloss: 1.17498\n",
      "[42]\tvalid_0's multi_logloss: 1.17042\n",
      "[43]\tvalid_0's multi_logloss: 1.1659\n",
      "[44]\tvalid_0's multi_logloss: 1.16139\n",
      "[45]\tvalid_0's multi_logloss: 1.15692\n",
      "[46]\tvalid_0's multi_logloss: 1.15246\n",
      "[47]\tvalid_0's multi_logloss: 1.14803\n",
      "[48]\tvalid_0's multi_logloss: 1.14363\n",
      "[49]\tvalid_0's multi_logloss: 1.13926\n",
      "[50]\tvalid_0's multi_logloss: 1.1349\n",
      "[51]\tvalid_0's multi_logloss: 1.13057\n",
      "[52]\tvalid_0's multi_logloss: 1.12626\n",
      "[53]\tvalid_0's multi_logloss: 1.12197\n",
      "[54]\tvalid_0's multi_logloss: 1.11771\n",
      "[55]\tvalid_0's multi_logloss: 1.11347\n",
      "[56]\tvalid_0's multi_logloss: 1.10925\n",
      "[57]\tvalid_0's multi_logloss: 1.10506\n",
      "[58]\tvalid_0's multi_logloss: 1.10088\n",
      "[59]\tvalid_0's multi_logloss: 1.09673\n",
      "[60]\tvalid_0's multi_logloss: 1.09261\n",
      "[61]\tvalid_0's multi_logloss: 1.0885\n",
      "[62]\tvalid_0's multi_logloss: 1.08442\n",
      "[63]\tvalid_0's multi_logloss: 1.08036\n",
      "[64]\tvalid_0's multi_logloss: 1.07631\n",
      "[65]\tvalid_0's multi_logloss: 1.07229\n",
      "[66]\tvalid_0's multi_logloss: 1.06829\n",
      "[67]\tvalid_0's multi_logloss: 1.0643\n",
      "[68]\tvalid_0's multi_logloss: 1.06034\n",
      "[69]\tvalid_0's multi_logloss: 1.0564\n",
      "[70]\tvalid_0's multi_logloss: 1.05248\n",
      "[71]\tvalid_0's multi_logloss: 1.04858\n",
      "[72]\tvalid_0's multi_logloss: 1.04469\n",
      "[73]\tvalid_0's multi_logloss: 1.04083\n",
      "[74]\tvalid_0's multi_logloss: 1.03698\n",
      "[75]\tvalid_0's multi_logloss: 1.03315\n",
      "[76]\tvalid_0's multi_logloss: 1.02935\n",
      "[77]\tvalid_0's multi_logloss: 1.02556\n",
      "[78]\tvalid_0's multi_logloss: 1.02179\n",
      "[79]\tvalid_0's multi_logloss: 1.01804\n",
      "[80]\tvalid_0's multi_logloss: 1.0143\n",
      "[81]\tvalid_0's multi_logloss: 1.01059\n",
      "[82]\tvalid_0's multi_logloss: 1.00689\n",
      "[83]\tvalid_0's multi_logloss: 1.00321\n",
      "[84]\tvalid_0's multi_logloss: 0.999549\n",
      "[85]\tvalid_0's multi_logloss: 0.995902\n",
      "[86]\tvalid_0's multi_logloss: 0.992279\n",
      "[87]\tvalid_0's multi_logloss: 0.988673\n",
      "[88]\tvalid_0's multi_logloss: 0.985078\n",
      "[89]\tvalid_0's multi_logloss: 0.981507\n",
      "[90]\tvalid_0's multi_logloss: 0.977947\n",
      "[91]\tvalid_0's multi_logloss: 0.974405\n",
      "[92]\tvalid_0's multi_logloss: 0.970885\n",
      "[93]\tvalid_0's multi_logloss: 0.967382\n",
      "[94]\tvalid_0's multi_logloss: 0.96389\n",
      "[95]\tvalid_0's multi_logloss: 0.960416\n",
      "[96]\tvalid_0's multi_logloss: 0.956963\n",
      "[97]\tvalid_0's multi_logloss: 0.953521\n",
      "[98]\tvalid_0's multi_logloss: 0.950101\n",
      "[99]\tvalid_0's multi_logloss: 0.946697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's multi_logloss: 0.943303\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.943303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       0.97      1.00      0.99       302\n",
      "           3       0.98      0.98      0.98       327\n",
      "\n",
      "    accuracy                           0.99      1279\n",
      "   macro avg       0.99      0.99      0.99      1279\n",
      "weighted avg       0.99      0.99      0.99      1279\n",
      "\n",
      "[[329   0   3   7]\n",
      " [  0 310   1   0]\n",
      " [  0   0 302   0]\n",
      " [  0   1   4 322]]\n",
      "Accuracy: 98.75%\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.002\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.002,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "91b50dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.36375\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.341\n",
      "[3]\tvalid_0's multi_logloss: 1.31884\n",
      "[4]\tvalid_0's multi_logloss: 1.29727\n",
      "[5]\tvalid_0's multi_logloss: 1.27624\n",
      "[6]\tvalid_0's multi_logloss: 1.25574\n",
      "[7]\tvalid_0's multi_logloss: 1.23574\n",
      "[8]\tvalid_0's multi_logloss: 1.21618\n",
      "[9]\tvalid_0's multi_logloss: 1.19707\n",
      "[10]\tvalid_0's multi_logloss: 1.17843\n",
      "[11]\tvalid_0's multi_logloss: 1.1602\n",
      "[12]\tvalid_0's multi_logloss: 1.14237\n",
      "[13]\tvalid_0's multi_logloss: 1.12495\n",
      "[14]\tvalid_0's multi_logloss: 1.10787\n",
      "[15]\tvalid_0's multi_logloss: 1.09117\n",
      "[16]\tvalid_0's multi_logloss: 1.07484\n",
      "[17]\tvalid_0's multi_logloss: 1.05882\n",
      "[18]\tvalid_0's multi_logloss: 1.04315\n",
      "[19]\tvalid_0's multi_logloss: 1.02779\n",
      "[20]\tvalid_0's multi_logloss: 1.0127\n",
      "[21]\tvalid_0's multi_logloss: 0.997921\n",
      "[22]\tvalid_0's multi_logloss: 0.983413\n",
      "[23]\tvalid_0's multi_logloss: 0.969186\n",
      "[24]\tvalid_0's multi_logloss: 0.955254\n",
      "[25]\tvalid_0's multi_logloss: 0.941564\n",
      "[26]\tvalid_0's multi_logloss: 0.928155\n",
      "[27]\tvalid_0's multi_logloss: 0.914996\n",
      "[28]\tvalid_0's multi_logloss: 0.902061\n",
      "[29]\tvalid_0's multi_logloss: 0.889384\n",
      "[30]\tvalid_0's multi_logloss: 0.876914\n",
      "[31]\tvalid_0's multi_logloss: 0.864636\n",
      "[32]\tvalid_0's multi_logloss: 0.852576\n",
      "[33]\tvalid_0's multi_logloss: 0.840718\n",
      "[34]\tvalid_0's multi_logloss: 0.829073\n",
      "[35]\tvalid_0's multi_logloss: 0.81763\n",
      "[36]\tvalid_0's multi_logloss: 0.806388\n",
      "[37]\tvalid_0's multi_logloss: 0.795341\n",
      "[38]\tvalid_0's multi_logloss: 0.784482\n",
      "[39]\tvalid_0's multi_logloss: 0.773805\n",
      "[40]\tvalid_0's multi_logloss: 0.763309\n",
      "[41]\tvalid_0's multi_logloss: 0.752989\n",
      "[42]\tvalid_0's multi_logloss: 0.742842\n",
      "[43]\tvalid_0's multi_logloss: 0.73286\n",
      "[44]\tvalid_0's multi_logloss: 0.723039\n",
      "[45]\tvalid_0's multi_logloss: 0.713381\n",
      "[46]\tvalid_0's multi_logloss: 0.703881\n",
      "[47]\tvalid_0's multi_logloss: 0.694529\n",
      "[48]\tvalid_0's multi_logloss: 0.685334\n",
      "[49]\tvalid_0's multi_logloss: 0.676289\n",
      "[50]\tvalid_0's multi_logloss: 0.667387\n",
      "[51]\tvalid_0's multi_logloss: 0.658627\n",
      "[52]\tvalid_0's multi_logloss: 0.650002\n",
      "[53]\tvalid_0's multi_logloss: 0.641499\n",
      "[54]\tvalid_0's multi_logloss: 0.633127\n",
      "[55]\tvalid_0's multi_logloss: 0.624881\n",
      "[56]\tvalid_0's multi_logloss: 0.616765\n",
      "[57]\tvalid_0's multi_logloss: 0.608771\n",
      "[58]\tvalid_0's multi_logloss: 0.6009\n",
      "[59]\tvalid_0's multi_logloss: 0.593149\n",
      "[60]\tvalid_0's multi_logloss: 0.585519\n",
      "[61]\tvalid_0's multi_logloss: 0.578001\n",
      "[62]\tvalid_0's multi_logloss: 0.570596\n",
      "[63]\tvalid_0's multi_logloss: 0.563312\n",
      "[64]\tvalid_0's multi_logloss: 0.55614\n",
      "[65]\tvalid_0's multi_logloss: 0.549077\n",
      "[66]\tvalid_0's multi_logloss: 0.542118\n",
      "[67]\tvalid_0's multi_logloss: 0.535261\n",
      "[68]\tvalid_0's multi_logloss: 0.528504\n",
      "[69]\tvalid_0's multi_logloss: 0.521847\n",
      "[70]\tvalid_0's multi_logloss: 0.51529\n",
      "[71]\tvalid_0's multi_logloss: 0.508783\n",
      "[72]\tvalid_0's multi_logloss: 0.502373\n",
      "[73]\tvalid_0's multi_logloss: 0.496058\n",
      "[74]\tvalid_0's multi_logloss: 0.489831\n",
      "[75]\tvalid_0's multi_logloss: 0.483697\n",
      "[76]\tvalid_0's multi_logloss: 0.477651\n",
      "[77]\tvalid_0's multi_logloss: 0.471688\n",
      "[78]\tvalid_0's multi_logloss: 0.465813\n",
      "[79]\tvalid_0's multi_logloss: 0.460019\n",
      "[80]\tvalid_0's multi_logloss: 0.454313\n",
      "[81]\tvalid_0's multi_logloss: 0.448692\n",
      "[82]\tvalid_0's multi_logloss: 0.443144\n",
      "[83]\tvalid_0's multi_logloss: 0.437676\n",
      "[84]\tvalid_0's multi_logloss: 0.432287\n",
      "[85]\tvalid_0's multi_logloss: 0.42697\n",
      "[86]\tvalid_0's multi_logloss: 0.421726\n",
      "[87]\tvalid_0's multi_logloss: 0.416557\n",
      "[88]\tvalid_0's multi_logloss: 0.41146\n",
      "[89]\tvalid_0's multi_logloss: 0.406436\n",
      "[90]\tvalid_0's multi_logloss: 0.401474\n",
      "[91]\tvalid_0's multi_logloss: 0.396588\n",
      "[92]\tvalid_0's multi_logloss: 0.39177\n",
      "[93]\tvalid_0's multi_logloss: 0.38702\n",
      "[94]\tvalid_0's multi_logloss: 0.38233\n",
      "[95]\tvalid_0's multi_logloss: 0.377707\n",
      "[96]\tvalid_0's multi_logloss: 0.373147\n",
      "[97]\tvalid_0's multi_logloss: 0.368647\n",
      "[98]\tvalid_0's multi_logloss: 0.36421\n",
      "[99]\tvalid_0's multi_logloss: 0.359831\n",
      "[100]\tvalid_0's multi_logloss: 0.355514\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.355514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.98      1.00      0.99       327\n",
      "\n",
      "    accuracy                           0.99      1279\n",
      "   macro avg       0.99      0.99      0.99      1279\n",
      "weighted avg       0.99      0.99      0.99      1279\n",
      "\n",
      "[[332   1   0   6]\n",
      " [  0 310   1   0]\n",
      " [  0   0 302   0]\n",
      " [  0   0   0 327]]\n",
      "Accuracy: 99.37%\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.008\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.008,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "e8a155c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.36084\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.33535\n",
      "[3]\tvalid_0's multi_logloss: 1.3106\n",
      "[4]\tvalid_0's multi_logloss: 1.28657\n",
      "[5]\tvalid_0's multi_logloss: 1.26322\n",
      "[6]\tvalid_0's multi_logloss: 1.24052\n",
      "[7]\tvalid_0's multi_logloss: 1.21843\n",
      "[8]\tvalid_0's multi_logloss: 1.19689\n",
      "[9]\tvalid_0's multi_logloss: 1.1759\n",
      "[10]\tvalid_0's multi_logloss: 1.15547\n",
      "[11]\tvalid_0's multi_logloss: 1.13556\n",
      "[12]\tvalid_0's multi_logloss: 1.11612\n",
      "[13]\tvalid_0's multi_logloss: 1.09715\n",
      "[14]\tvalid_0's multi_logloss: 1.07863\n",
      "[15]\tvalid_0's multi_logloss: 1.06053\n",
      "[16]\tvalid_0's multi_logloss: 1.04287\n",
      "[17]\tvalid_0's multi_logloss: 1.02556\n",
      "[18]\tvalid_0's multi_logloss: 1.00868\n",
      "[19]\tvalid_0's multi_logloss: 0.992156\n",
      "[20]\tvalid_0's multi_logloss: 0.975969\n",
      "[21]\tvalid_0's multi_logloss: 0.960157\n",
      "[22]\tvalid_0's multi_logloss: 0.94466\n",
      "[23]\tvalid_0's multi_logloss: 0.929493\n",
      "[24]\tvalid_0's multi_logloss: 0.914668\n",
      "[25]\tvalid_0's multi_logloss: 0.90013\n",
      "[26]\tvalid_0's multi_logloss: 0.885915\n",
      "[27]\tvalid_0's multi_logloss: 0.871925\n",
      "[28]\tvalid_0's multi_logloss: 0.85822\n",
      "[29]\tvalid_0's multi_logloss: 0.844772\n",
      "[30]\tvalid_0's multi_logloss: 0.831594\n",
      "[31]\tvalid_0's multi_logloss: 0.818681\n",
      "[32]\tvalid_0's multi_logloss: 0.80602\n",
      "[33]\tvalid_0's multi_logloss: 0.793604\n",
      "[34]\tvalid_0's multi_logloss: 0.781427\n",
      "[35]\tvalid_0's multi_logloss: 0.769483\n",
      "[36]\tvalid_0's multi_logloss: 0.757763\n",
      "[37]\tvalid_0's multi_logloss: 0.746264\n",
      "[38]\tvalid_0's multi_logloss: 0.734974\n",
      "[39]\tvalid_0's multi_logloss: 0.723894\n",
      "[40]\tvalid_0's multi_logloss: 0.71302\n",
      "[41]\tvalid_0's multi_logloss: 0.702348\n",
      "[42]\tvalid_0's multi_logloss: 0.691853\n",
      "[43]\tvalid_0's multi_logloss: 0.681567\n",
      "[44]\tvalid_0's multi_logloss: 0.671462\n",
      "[45]\tvalid_0's multi_logloss: 0.661541\n",
      "[46]\tvalid_0's multi_logloss: 0.651791\n",
      "[47]\tvalid_0's multi_logloss: 0.642199\n",
      "[48]\tvalid_0's multi_logloss: 0.632774\n",
      "[49]\tvalid_0's multi_logloss: 0.623509\n",
      "[50]\tvalid_0's multi_logloss: 0.614404\n",
      "[51]\tvalid_0's multi_logloss: 0.60546\n",
      "[52]\tvalid_0's multi_logloss: 0.596667\n",
      "[53]\tvalid_0's multi_logloss: 0.588026\n",
      "[54]\tvalid_0's multi_logloss: 0.57953\n",
      "[55]\tvalid_0's multi_logloss: 0.571183\n",
      "[56]\tvalid_0's multi_logloss: 0.562981\n",
      "[57]\tvalid_0's multi_logloss: 0.554923\n",
      "[58]\tvalid_0's multi_logloss: 0.547001\n",
      "[59]\tvalid_0's multi_logloss: 0.539212\n",
      "[60]\tvalid_0's multi_logloss: 0.531551\n",
      "[61]\tvalid_0's multi_logloss: 0.524015\n",
      "[62]\tvalid_0's multi_logloss: 0.516604\n",
      "[63]\tvalid_0's multi_logloss: 0.509312\n",
      "[64]\tvalid_0's multi_logloss: 0.502094\n",
      "[65]\tvalid_0's multi_logloss: 0.494995\n",
      "[66]\tvalid_0's multi_logloss: 0.48801\n",
      "[67]\tvalid_0's multi_logloss: 0.481142\n",
      "[68]\tvalid_0's multi_logloss: 0.474387\n",
      "[69]\tvalid_0's multi_logloss: 0.467734\n",
      "[70]\tvalid_0's multi_logloss: 0.461192\n",
      "[71]\tvalid_0's multi_logloss: 0.454762\n",
      "[72]\tvalid_0's multi_logloss: 0.448429\n",
      "[73]\tvalid_0's multi_logloss: 0.442199\n",
      "[74]\tvalid_0's multi_logloss: 0.436063\n",
      "[75]\tvalid_0's multi_logloss: 0.430025\n",
      "[76]\tvalid_0's multi_logloss: 0.424086\n",
      "[77]\tvalid_0's multi_logloss: 0.418239\n",
      "[78]\tvalid_0's multi_logloss: 0.41248\n",
      "[79]\tvalid_0's multi_logloss: 0.406813\n",
      "[80]\tvalid_0's multi_logloss: 0.401234\n",
      "[81]\tvalid_0's multi_logloss: 0.395743\n",
      "[82]\tvalid_0's multi_logloss: 0.390337\n",
      "[83]\tvalid_0's multi_logloss: 0.385016\n",
      "[84]\tvalid_0's multi_logloss: 0.379779\n",
      "[85]\tvalid_0's multi_logloss: 0.374616\n",
      "[86]\tvalid_0's multi_logloss: 0.369535\n",
      "[87]\tvalid_0's multi_logloss: 0.364531\n",
      "[88]\tvalid_0's multi_logloss: 0.359605\n",
      "[89]\tvalid_0's multi_logloss: 0.354752\n",
      "[90]\tvalid_0's multi_logloss: 0.349971\n",
      "[91]\tvalid_0's multi_logloss: 0.345266\n",
      "[92]\tvalid_0's multi_logloss: 0.34063\n",
      "[93]\tvalid_0's multi_logloss: 0.336063\n",
      "[94]\tvalid_0's multi_logloss: 0.331566\n",
      "[95]\tvalid_0's multi_logloss: 0.327136\n",
      "[96]\tvalid_0's multi_logloss: 0.322772\n",
      "[97]\tvalid_0's multi_logloss: 0.318473\n",
      "[98]\tvalid_0's multi_logloss: 0.314236\n",
      "[99]\tvalid_0's multi_logloss: 0.310039\n",
      "[100]\tvalid_0's multi_logloss: 0.305927\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.305927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       339\n",
      "           1       1.00      1.00      1.00       311\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       0.98      1.00      0.99       327\n",
      "\n",
      "    accuracy                           0.99      1279\n",
      "   macro avg       0.99      0.99      0.99      1279\n",
      "weighted avg       0.99      0.99      0.99      1279\n",
      "\n",
      "[[332   1   0   6]\n",
      " [  0 310   1   0]\n",
      " [  0   0 302   0]\n",
      " [  0   0   0 327]]\n",
      "Accuracy: 99.37%\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.009\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.009,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537a682e",
   "metadata": {},
   "source": [
    "# We see that learning rate = 0.05 gives best accuracy and Number of leaves = 7 give best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "6e989a09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we got importance of features owing to the data\n",
    "lgb.plot_importance(model, height=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb423fd4",
   "metadata": {},
   "source": [
    "# Implementing LBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1ac00f9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2857\n",
      "[LightGBM] [Info] Number of data points in the train set: 909, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.387395\n",
      "[LightGBM] [Info] Start training from score -1.400699\n",
      "[LightGBM] [Info] Start training from score -1.470011\n",
      "[LightGBM] [Info] Start training from score -1.294892\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 1.25413\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.13555\n",
      "[3]\tvalid_0's multi_logloss: 1.03346\n",
      "[4]\tvalid_0's multi_logloss: 0.944058\n",
      "[5]\tvalid_0's multi_logloss: 0.865496\n",
      "[6]\tvalid_0's multi_logloss: 0.795786\n",
      "[7]\tvalid_0's multi_logloss: 0.73293\n",
      "[8]\tvalid_0's multi_logloss: 0.676518\n",
      "[9]\tvalid_0's multi_logloss: 0.625579\n",
      "[10]\tvalid_0's multi_logloss: 0.579156\n",
      "[11]\tvalid_0's multi_logloss: 0.536942\n",
      "[12]\tvalid_0's multi_logloss: 0.49833\n",
      "[13]\tvalid_0's multi_logloss: 0.463105\n",
      "[14]\tvalid_0's multi_logloss: 0.430882\n",
      "[15]\tvalid_0's multi_logloss: 0.401149\n",
      "[16]\tvalid_0's multi_logloss: 0.374048\n",
      "[17]\tvalid_0's multi_logloss: 0.349139\n",
      "[18]\tvalid_0's multi_logloss: 0.326092\n",
      "[19]\tvalid_0's multi_logloss: 0.304913\n",
      "[20]\tvalid_0's multi_logloss: 0.285369\n",
      "[21]\tvalid_0's multi_logloss: 0.267284\n",
      "[22]\tvalid_0's multi_logloss: 0.250538\n",
      "[23]\tvalid_0's multi_logloss: 0.235133\n",
      "[24]\tvalid_0's multi_logloss: 0.220642\n",
      "[25]\tvalid_0's multi_logloss: 0.207446\n",
      "[26]\tvalid_0's multi_logloss: 0.194918\n",
      "[27]\tvalid_0's multi_logloss: 0.183324\n",
      "[28]\tvalid_0's multi_logloss: 0.172589\n",
      "[29]\tvalid_0's multi_logloss: 0.162101\n",
      "[30]\tvalid_0's multi_logloss: 0.152382\n",
      "[31]\tvalid_0's multi_logloss: 0.143554\n",
      "[32]\tvalid_0's multi_logloss: 0.134901\n",
      "[33]\tvalid_0's multi_logloss: 0.126876\n",
      "[34]\tvalid_0's multi_logloss: 0.119459\n",
      "[35]\tvalid_0's multi_logloss: 0.112631\n",
      "[36]\tvalid_0's multi_logloss: 0.106341\n",
      "[37]\tvalid_0's multi_logloss: 0.100503\n",
      "[38]\tvalid_0's multi_logloss: 0.095118\n",
      "[39]\tvalid_0's multi_logloss: 0.0901264\n",
      "[40]\tvalid_0's multi_logloss: 0.0854107\n",
      "[41]\tvalid_0's multi_logloss: 0.0811585\n",
      "[42]\tvalid_0's multi_logloss: 0.077264\n",
      "[43]\tvalid_0's multi_logloss: 0.0735459\n",
      "[44]\tvalid_0's multi_logloss: 0.0702088\n",
      "[45]\tvalid_0's multi_logloss: 0.0670652\n",
      "[46]\tvalid_0's multi_logloss: 0.0640739\n",
      "[47]\tvalid_0's multi_logloss: 0.0613769\n",
      "[48]\tvalid_0's multi_logloss: 0.0587978\n",
      "[49]\tvalid_0's multi_logloss: 0.0564967\n",
      "[50]\tvalid_0's multi_logloss: 0.0541314\n",
      "[51]\tvalid_0's multi_logloss: 0.0521407\n",
      "[52]\tvalid_0's multi_logloss: 0.050075\n",
      "[53]\tvalid_0's multi_logloss: 0.0482344\n",
      "[54]\tvalid_0's multi_logloss: 0.0464716\n",
      "[55]\tvalid_0's multi_logloss: 0.0450426\n",
      "[56]\tvalid_0's multi_logloss: 0.0435249\n",
      "[57]\tvalid_0's multi_logloss: 0.0422673\n",
      "[58]\tvalid_0's multi_logloss: 0.0410645\n",
      "[59]\tvalid_0's multi_logloss: 0.0398885\n",
      "[60]\tvalid_0's multi_logloss: 0.0389098\n",
      "[61]\tvalid_0's multi_logloss: 0.0378487\n",
      "[62]\tvalid_0's multi_logloss: 0.03696\n",
      "[63]\tvalid_0's multi_logloss: 0.035735\n",
      "[64]\tvalid_0's multi_logloss: 0.0350356\n",
      "[65]\tvalid_0's multi_logloss: 0.033895\n",
      "[66]\tvalid_0's multi_logloss: 0.0329441\n",
      "[67]\tvalid_0's multi_logloss: 0.0319024\n",
      "[68]\tvalid_0's multi_logloss: 0.0310084\n",
      "[69]\tvalid_0's multi_logloss: 0.0301398\n",
      "[70]\tvalid_0's multi_logloss: 0.0292981\n",
      "[71]\tvalid_0's multi_logloss: 0.0287788\n",
      "[72]\tvalid_0's multi_logloss: 0.0282796\n",
      "[73]\tvalid_0's multi_logloss: 0.0275328\n",
      "[74]\tvalid_0's multi_logloss: 0.0271484\n",
      "[75]\tvalid_0's multi_logloss: 0.0267432\n",
      "[76]\tvalid_0's multi_logloss: 0.0265176\n",
      "[77]\tvalid_0's multi_logloss: 0.026302\n",
      "[78]\tvalid_0's multi_logloss: 0.0260941\n",
      "[79]\tvalid_0's multi_logloss: 0.0257568\n",
      "[80]\tvalid_0's multi_logloss: 0.0253505\n",
      "[81]\tvalid_0's multi_logloss: 0.0249904\n",
      "[82]\tvalid_0's multi_logloss: 0.0246306\n",
      "[83]\tvalid_0's multi_logloss: 0.0243566\n",
      "[84]\tvalid_0's multi_logloss: 0.0238688\n",
      "[85]\tvalid_0's multi_logloss: 0.023577\n",
      "[86]\tvalid_0's multi_logloss: 0.0233855\n",
      "[87]\tvalid_0's multi_logloss: 0.0229945\n",
      "[88]\tvalid_0's multi_logloss: 0.0227864\n",
      "[89]\tvalid_0's multi_logloss: 0.0226226\n",
      "[90]\tvalid_0's multi_logloss: 0.0225493\n",
      "[91]\tvalid_0's multi_logloss: 0.022374\n",
      "[92]\tvalid_0's multi_logloss: 0.0221118\n",
      "[93]\tvalid_0's multi_logloss: 0.0219986\n",
      "[94]\tvalid_0's multi_logloss: 0.0219695\n",
      "[95]\tvalid_0's multi_logloss: 0.0219578\n",
      "[96]\tvalid_0's multi_logloss: 0.0219558\n",
      "[97]\tvalid_0's multi_logloss: 0.0218687\n",
      "[98]\tvalid_0's multi_logloss: 0.0218619\n",
      "[99]\tvalid_0's multi_logloss: 0.0217554\n",
      "[100]\tvalid_0's multi_logloss: 0.0216692\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.0216692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       335\n",
      "           1       1.00      1.00      1.00       158\n",
      "           2       1.00      1.00      1.00        26\n",
      "           3       0.80      0.89      0.84         9\n",
      "\n",
      "    accuracy                           0.99       528\n",
      "   macro avg       0.95      0.97      0.96       528\n",
      "weighted avg       0.99      0.99      0.99       528\n",
      "\n",
      "[[333   0   0   2]\n",
      " [  0 158   0   0]\n",
      " [  0   0  26   0]\n",
      " [  1   0   0   8]]\n",
      "Accuracy: 99.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(X_train, Y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, Y_test, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "Y_pred = argmax(Y_pred, axis=1)\n",
    "cr = classification_report(Y_test, Y_pred)\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d8ae86",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "dd399040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "228\n",
      "Accuracy: 98.25%\n"
     ]
    }
   ],
   "source": [
    "# Validation and tuning\n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 10\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "511a992d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "228\n",
      "Accuracy: 98.68%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 15\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "cc3ddd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "228\n",
      "Accuracy: 99.12%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 20\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "1c9dde35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "228\n",
      "Accuracy: 99.12%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 25\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b7a5e456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "228\n",
      "Accuracy: 99.56%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 30\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ae5430b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "228\n",
      "Accuracy: 99.56%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 35\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "717701dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "228\n",
      "Accuracy: 99.56%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 40\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0bb6c8",
   "metadata": {},
   "source": [
    "# Epoch = 15 gives best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e9a564f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "228\n",
      "Accuracy: 98.68%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 2,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 20\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "86e712ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "228\n",
      "Accuracy: 98.25%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 1,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 20\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5b6eb866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "228\n",
      "Accuracy: 99.12%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 20\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "03f9fa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "228\n",
      "Accuracy: 99.12%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 4,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 20\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d299e6a9",
   "metadata": {},
   "source": [
    "# Max_depth = 2 gives the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "22625278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.48%\n"
     ]
    }
   ],
   "source": [
    "train = xgb.DMatrix(X_train, label = Y_train)\n",
    "test = xgb.DMatrix(X_test, label = Y_test)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 2,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 20\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521da2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
